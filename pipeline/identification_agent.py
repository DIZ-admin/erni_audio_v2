"""
IdentificationAgent –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Å–ø–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ pyannote.ai API
"""

import logging
import time
from pathlib import Path
from typing import Dict, List, Optional
import requests
from .pyannote_media_agent import PyannoteMediaAgent


class IdentificationAgent:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Å–ø–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ pyannote.ai Identification API.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é –∞—É–¥–∏–æ –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤ —Å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º–∏
    –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ –æ—Ç–ø–µ—á–∞—Ç–∫–∞–º–∏ (voiceprints).
    """
    
    def __init__(self, api_key: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IdentificationAgent.
        
        Args:
            api_key: API –∫–ª—é—á pyannote.ai
        """
        self.api_key = api_key
        self.base_url = "https://api.pyannote.ai/v1"
        self.logger = logging.getLogger(__name__)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–¥–∏–∞ –∞–≥–µ–Ω—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
        self.media_agent = PyannoteMediaAgent(api_key)
        
        self.logger.info("‚úÖ IdentificationAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def run(self,
            audio_file: Path,
            voiceprints: List[Dict],
            num_speakers: Optional[int] = None,
            confidence: bool = True,
            matching_threshold: float = 0.0,
            exclusive_matching: bool = True) -> List[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é —Å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Å–ø–∏–∫–µ—Ä–æ–≤.
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ URL
            voiceprints: –°–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç–ø–µ—á–∞—Ç–∫–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
                        [{"label": "John Doe", "voiceprint": "base64_data"}, ...]
            num_speakers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (None –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
            confidence: –í–∫–ª—é—á–∏—Ç—å –ª–∏ confidence scores
            matching_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è (0.0-1.0)
            exclusive_matching: –≠–∫—Å–∫–ª—é–∑–∏–≤–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (–æ–¥–∏–Ω voiceprint = –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π:
            [{"start": float, "end": float, "speaker": str, "confidence": float}, ...]
        """
        start_time = time.time()
        
        try:
            if not voiceprints:
                raise ValueError("–°–ø–∏—Å–æ–∫ voiceprints –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
            self._validate_audio_file(audio_file)
            
            file_size_mb = audio_file.stat().st_size / (1024 * 1024)
            self.logger.info(f"üéµ –ù–∞—á–∏–Ω–∞—é –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é: {audio_file.name} ({file_size_mb:.1f}MB)")
            self.logger.info(f"üë• Voiceprints: {len(voiceprints)} ({', '.join([vp['label'] for vp in voiceprints])})")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –≤ pyannote.ai –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            self.logger.info("üì§ –ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª –≤ pyannote.ai...")
            media_url = self.media_agent.upload_file(audio_file)
            self.logger.info(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {media_url}")
            
            # –°–æ–∑–¥–∞–µ–º identification job
            job_id = self._submit_identification_job(
                media_url, voiceprints, num_speakers, confidence, 
                matching_threshold, exclusive_matching
            )
            self.logger.info(f"üöÄ Identification job –∑–∞–ø—É—â–µ–Ω: {job_id}")
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            segments = self._wait_for_completion(job_id)
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            duration = time.time() - start_time
            speakers = set(seg["speaker"] for seg in segments)
            self.logger.info(f"‚úÖ –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∑–∞ {duration:.2f}—Å")
            self.logger.info(f"üë• –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {len(speakers)} ({', '.join(sorted(speakers))})")
            
            return segments
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            raise RuntimeError(f"–û—à–∏–±–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}") from e
    
    def _validate_audio_file(self, audio_file: Path) -> None:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –¥–ª—è identification."""
        if not audio_file.exists():
            raise FileNotFoundError(f"–ê—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
        
        file_size_mb = audio_file.stat().st_size / (1024 * 1024)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–ª–∏–º–∏—Ç pyannote.ai: 1GB)
        if file_size_mb > 1024:
            raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size_mb:.1f}MB (–º–∞–∫—Å–∏–º—É–º 1GB)")
        
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–ª–∏–º–∏—Ç pyannote.ai: 24 —á–∞—Å–∞)
        if file_size_mb > 100:  # –ü—Ä–∏–º–µ—Ä–Ω–æ 50 –º–∏–Ω—É—Ç –¥–ª—è WAV
            self.logger.warning(f"‚ö†Ô∏è –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {file_size_mb:.1f}MB, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏")
    
    def _submit_identification_job(self, 
                                  media_url: str,
                                  voiceprints: List[Dict],
                                  num_speakers: Optional[int],
                                  confidence: bool,
                                  matching_threshold: float,
                                  exclusive_matching: bool) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É –Ω–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é."""
        url = f"{self.base_url}/identify"
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "url": media_url,
            "voiceprints": voiceprints,
            "matching": {
                "threshold": matching_threshold,
                "exclusive": exclusive_matching
            }
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if num_speakers is not None:
            data["numSpeakers"] = num_speakers
            self.logger.info(f"üéØ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {num_speakers}")
        
        if confidence:
            data["confidence"] = True
            self.logger.info("üìä –í–∫–ª—é—á–µ–Ω—ã confidence scores")

        self.logger.debug(f"üîç –û—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ API: {data}")

        response = requests.post(url, json=data, headers=headers, timeout=30)
        
        if response.status_code != 200:
            error_msg = f"HTTP {response.status_code}"
            try:
                error_detail = response.json().get("detail", "Unknown error")
                error_msg += f": {error_detail}"
            except:
                error_msg += f": {response.text}"
            raise RuntimeError(f"–û—à–∏–±–∫–∞ pyannote.ai API: {error_msg}")
        
        result = response.json()
        return result["jobId"]
    
    def _wait_for_completion(self, job_id: str, max_wait_seconds: int = 1800) -> List[Dict]:
        """–ñ–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è identification job –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã."""
        url = f"{self.base_url}/jobs/{job_id}"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        
        start_time = time.time()
        retry_count = 0
        
        while time.time() - start_time < max_wait_seconds:
            try:
                response = requests.get(url, headers=headers, timeout=30)
                
                if response.status_code != 200:
                    raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ job: HTTP {response.status_code}")
                
                job_data = response.json()
                status = job_data.get("status")
                
                if status == "succeeded":
                    output = job_data.get("output", {})
                    self.logger.debug(f"üîç –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç API: {output}")

                    # –î–ª—è identification API –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø–æ–ª–µ "identification"
                    identification = output.get("identification", [])

                    if identification:
                        self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: {len(identification)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                        return self._process_identification_segments(identification)

                    # Fallback –Ω–∞ –æ–±—ã—á–Ω—É—é –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é –µ—Å–ª–∏ identification –ø—É—Å—Ç
                    diarization = output.get("diarization", [])
                    if diarization:
                        self.logger.warning("‚ö†Ô∏è Identification –ø—É—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é")
                        return self._process_segments(diarization)

                    # Fallback –Ω–∞ segments
                    segments = output.get("segments", [])
                    if segments:
                        self.logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º segments –∫–∞–∫ fallback")
                        return self._process_segments(segments)

                    self.logger.warning("‚ö†Ô∏è Identification job –∑–∞–≤–µ—Ä—à–µ–Ω, –Ω–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    self.logger.debug(f"üîç –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª—è –≤ output: {list(output.keys())}")
                    return []
                
                elif status == "failed":
                    error_msg = job_data.get("output", {}).get("error", "Unknown error")
                    raise RuntimeError(f"Identification job failed: {error_msg}")
                
                elif status == "canceled":
                    raise RuntimeError("Identification job –±—ã–ª –æ—Ç–º–µ–Ω–µ–Ω")
                
                elif status in ["created", "processing", "running"]:
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∂–¥–∞—Ç—å
                    retry_count += 1
                    if retry_count <= 5:
                        self.logger.debug(f"Identification job {job_id} –≤ —Å—Ç–∞—Ç—É—Å–µ '{status}', –∂–¥–µ–º...")
                    elif retry_count % 10 == 0:
                        elapsed = time.time() - start_time
                        self.logger.info(f"‚è≥ Identification job {job_id} –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —É–∂–µ {elapsed:.1f}—Å...")

                    time.sleep(5)
                    continue
                
                else:
                    raise RuntimeError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å identification job: {status}")
                    
            except requests.RequestException as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ identification job: {e}")
                time.sleep(10)
                continue
        
        raise RuntimeError(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è identification job ({max_wait_seconds}—Å)")
    
    def _process_identification_segments(self, identification: List[Dict]) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç identification —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑ pyannote.ai."""
        processed_segments = []

        for segment in identification:
            # Identification API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Å –ø–æ–ª–µ–º "speaker" (—É–∂–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è)
            processed_segment = {
                "start": float(segment.get("start", 0.0)),
                "end": float(segment.get("end", 0.0)),
                "speaker": segment.get("speaker", "UNKNOWN"),
                "confidence": 1.0,  # –î–ª—è identification –∏—Å–ø–æ–ª—å–∑—É–µ–º 1.0 –∫–∞–∫ –±–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                "match": segment.get("match"),  # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π voiceprint –∏–ª–∏ None
                "diarization_speaker": segment.get("diarizationSpeaker", "UNKNOWN")  # –ò—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏–∫–µ—Ä –∏–∑ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
            }

            processed_segments.append(processed_segment)

        self.logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_segments)} identification —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return processed_segments

    def _process_segments(self, segments: List[Dict]) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑ pyannote.ai –≤ –Ω–∞—à —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."""
        processed_segments = []

        for segment in segments:
            processed_segment = {
                "start": float(segment.get("start", 0.0)),
                "end": float(segment.get("end", 0.0)),
                "speaker": segment.get("speaker", "UNKNOWN"),
                "confidence": segment.get("confidence", 0.0)
            }

            processed_segments.append(processed_segment)

        self.logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        return processed_segments
    
    def estimate_cost(self, audio_file: Path, num_voiceprints: int) -> Dict[str, any]:
        """
        –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
            num_voiceprints: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ voiceprints –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        """
        file_size_mb = audio_file.stat().st_size / (1024 * 1024)
        
        # –°—Ç–æ–∏–º–æ—Å—Ç—å identification –≤ pyannote.ai (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)
        # –û–±—ã—á–Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ voiceprints
        base_cost = 0.05  # –ë–∞–∑–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å
        size_cost = file_size_mb * 0.01  # –ó–∞ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        voiceprint_cost = num_voiceprints * 0.005  # –ó–∞ –∫–∞–∂–¥—ã–π voiceprint
        
        estimated_cost = base_cost + size_cost + voiceprint_cost
        
        return {
            "estimated_cost_usd": round(estimated_cost, 4),
            "file_size_mb": round(file_size_mb, 1),
            "num_voiceprints": num_voiceprints,
            "note": "–ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞, —Ä–µ–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è"
        }
