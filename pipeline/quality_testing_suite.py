#!/usr/bin/env python3
"""
Quality Testing Suite - –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å transcription_quality_test.py, transcription_quality_tester.py –∏ real_wer_testing.py
"""

import argparse
import logging
import sys
import os
import time
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, str(Path(__file__).parent))

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # –ï—Å–ª–∏ python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä—É—á–Ω—É—é
    env_file = Path('.env')
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

from pipeline.transcription_agent import TranscriptionAgent
from pipeline.replicate_agent import ReplicateAgent
from pipeline.wer_evaluator import WERTranscriptionEvaluator, TranscriptionResult, WERCalculator


@dataclass
class TestScenario:
    """–¢–µ—Å—Ç–æ–≤—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
    name: str
    audio_file: Path
    reference_text: str
    description: str
    language: Optional[str] = None
    expected_speakers: Optional[int] = None


class QualityTestingSuite:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –≤–∏–¥–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    
    def __init__(self, openai_api_key: str, replicate_api_key: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
        
        Args:
            openai_api_key: OpenAI API –∫–ª—é—á
            replicate_api_key: Replicate API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.openai_api_key = openai_api_key
        self.replicate_api_key = replicate_api_key
        self.logger = logging.getLogger(__name__)
        self.evaluator = WERTranscriptionEvaluator()
        
        # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.openai_models = list(TranscriptionAgent.SUPPORTED_MODELS.keys())
        self.replicate_available = replicate_api_key is not None
        
        self.logger.info(f"üß™ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω QualityTestingSuite")
        self.logger.info(f"üìã OpenAI –º–æ–¥–µ–ª–∏: {', '.join(self.openai_models)}")
        self.logger.info(f"üöÄ Replicate –¥–æ—Å—Ç—É–ø–µ–Ω: {'–î–∞' if self.replicate_available else '–ù–µ—Ç'}")
    
    def create_test_scenarios(self, audio_files: List[str] = None, reference_texts: List[str] = None, 
                            use_real_files: bool = True) -> List[TestScenario]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        
        Args:
            audio_files: –°–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            reference_texts: –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
            use_real_files: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        """
        scenarios = []
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã
        if audio_files:
            scenarios = self._create_custom_scenarios(audio_files, reference_texts or [])
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
        elif use_real_files:
            scenarios = self._create_real_scenarios()
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞–µ–º –º–æ–∫–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        if not scenarios:
            scenarios = self._create_mock_scenarios()
        
        return scenarios
    
    def _create_custom_scenarios(self, audio_files: List[str], reference_texts: List[str]) -> List[TestScenario]:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏"""
        scenarios = []
        
        for i, audio_file in enumerate(audio_files):
            audio_path = Path(audio_file)
            if not audio_path.exists():
                self.logger.warning(f"‚ùå –ê—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_file}")
                continue
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π
            if i < len(reference_texts):
                reference_text = reference_texts[i]
            else:
                reference_text = self._find_reference_text(audio_path)
            
            scenario = TestScenario(
                name=audio_path.stem,
                audio_file=audio_path,
                reference_text=reference_text,
                description=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è {audio_path.name}",
                language=None,  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                expected_speakers=None  # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            )
            scenarios.append(scenario)
            self.logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π: {scenario.name}")
        
        return scenarios
    
    def _create_real_scenarios(self) -> List[TestScenario]:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        scenarios = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã
        test_files = [
            ("data/raw/Testdatei.m4a", "–ù–µ–º–µ—Ü–∫–∞—è —Ç–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å", "de"),
            ("data/raw/Sitzung Erweiterte GL 17.04.2025.m4a", "–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤—Å—Ç—Ä–µ—á–∞ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞", "de"),
            ("data/interim/Sitzung Erweiterte GL 17.04.2025_converted.wav", "–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—Å—Ç—Ä–µ—á–∞", "de"),
        ]
        
        for file_path, description, language in test_files:
            audio_path = Path(file_path)
            
            # –î–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ API –≤—ã–∑–æ–≤–æ–≤ –∏—â–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            segment_path = audio_path.parent / f"{audio_path.stem}_segment_2.0min{audio_path.suffix}"
            if segment_path.exists():
                audio_path = segment_path
                description += " (2-–º–∏–Ω—É—Ç–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç)"
            
            if audio_path.exists():
                reference_text = self._find_reference_text(audio_path, file_path)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–æ—á–Ω–æ–≥–æ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                accurate_reference_file = Path("data/raw") / f"{Path(file_path).stem}_accurate_reference.txt"
                if not accurate_reference_file.exists():
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è {audio_path.name}")
                    # –î–ª—è –¥–µ–º–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç
                    reference_text = self._generate_demo_reference_text(description, language)
                
                scenario = TestScenario(
                    name=audio_path.stem,
                    audio_file=audio_path,
                    reference_text=reference_text,
                    description=description,
                    language=language,
                    expected_speakers=2
                )
                scenarios.append(scenario)
                self.logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π: {scenario.name}")
        
        return scenarios
    
    def _create_mock_scenarios(self) -> List[TestScenario]:
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å –º–æ–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        mock_scenarios = []
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        test_audio = Path("tests/assets/test_audio_mock.wav")
        test_audio.parent.mkdir(parents=True, exist_ok=True)
        if not test_audio.exists():
            test_audio.write_bytes(b"RIFF" + b"\x00" * 44)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫
        
        scenario = TestScenario(
            name="mock_test",
            audio_file=test_audio,
            reference_text="–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.",
            description="–¢–µ—Å—Ç–æ–≤—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π —Å –º–æ–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏",
            language="ru",
            expected_speakers=1
        )
        mock_scenarios.append(scenario)
        
        return mock_scenarios
    
    def _find_reference_text(self, audio_path: Path, original_file_path: str = None) -> str:
        """–ò—â–µ—Ç —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        # –ï—Å–ª–∏ —ç—Ç–æ —Å–µ–≥–º–µ–Ω—Ç, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if original_file_path:
            original_stem = Path(original_file_path).stem
        else:
            if "_segment_" in audio_path.stem:
                original_stem = audio_path.stem.split("_segment_")[0]
            else:
                original_stem = audio_path.stem
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        accurate_reference_file = Path("data/raw") / f"{original_stem}_accurate_reference.txt"
        if accurate_reference_file.exists():
            return accurate_reference_file.read_text(encoding='utf-8').strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ñ–∞–π–ª
        reference_file = audio_path.parent / f"{original_stem}_reference.txt"
        if reference_file.exists():
            return reference_file.read_text(encoding='utf-8').strip()
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –≥–æ—Ç–æ–≤–æ–≥–æ —ç—Ç–∞–ª–æ–Ω–∞, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π
        return self._generate_demo_reference_text("–¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å", "de")
    
    def _generate_demo_reference_text(self, description: str, language: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        if language == "de":
            return ("Guten Tag, das ist eine Testaufnahme f√ºr die automatische Spracherkennung. "
                   "Wir testen heute verschiedene Modelle zur Transkription von deutschen Audiodateien.")
        elif language == "en":
            return ("Good day, this is a test recording for automatic speech recognition. "
                   "Today we are testing various models for transcribing English audio files.")
        else:
            return ("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. "
                   "–°–µ–≥–æ–¥–Ω—è –º—ã —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤.")
    
    def test_openai_model(self, model: str, scenario: TestScenario) -> TranscriptionResult:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç OpenAI –º–æ–¥–µ–ª—å –Ω–∞ —Å—Ü–µ–Ω–∞—Ä–∏–∏"""
        start_time = time.time()
        
        try:
            self.logger.info(f"üîÑ –¢–µ—Å—Ç–∏—Ä—É—é {model} –Ω–∞ {scenario.name}...")
            
            agent = TranscriptionAgent(
                api_key=self.openai_api_key,
                model=model,
                language=scenario.language
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏
            file_size_mb = scenario.audio_file.stat().st_size / (1024 * 1024)
            estimated_cost = agent.estimate_cost(file_size_mb)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            segments = agent.run(scenario.audio_file, "")
            
            processing_time = time.time() - start_time
            
            return TranscriptionResult(
                model_name=model,
                segments=segments,
                processing_time=processing_time,
                estimated_cost=estimated_cost,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è {model}: {e}")
            
            return TranscriptionResult(
                model_name=model,
                segments=[],
                processing_time=processing_time,
                estimated_cost="N/A",
                success=False,
                error=str(e)
            )
    
    def test_replicate_model(self, scenario: TestScenario) -> Optional[TranscriptionResult]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç Replicate –º–æ–¥–µ–ª—å –Ω–∞ —Å—Ü–µ–Ω–∞—Ä–∏–∏"""
        if not self.replicate_available:
            return None
        
        start_time = time.time()
        
        try:
            self.logger.info(f"üöÄ –¢–µ—Å—Ç–∏—Ä—É—é Replicate –Ω–∞ {scenario.name}...")
            
            agent = ReplicateAgent(api_token=self.replicate_api_key)
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏
            cost_info = agent.estimate_cost(scenario.audio_file)
            estimated_cost = f"~${cost_info['estimated_cost_usd']}"
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            segments = agent.run(
                audio_file=scenario.audio_file,
                num_speakers=scenario.expected_speakers,
                language=scenario.language
            )
            
            processing_time = time.time() - start_time
            
            return TranscriptionResult(
                model_name="replicate-whisper-diarization",
                segments=segments,
                processing_time=processing_time,
                estimated_cost=estimated_cost,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Replicate: {e}")
            
            return TranscriptionResult(
                model_name="replicate-whisper-diarization",
                segments=[],
                processing_time=processing_time,
                estimated_cost="N/A",
                success=False,
                error=str(e)
            )

    def run_comprehensive_test(self, scenarios: Optional[List[TestScenario]] = None,
                             models: List[str] = None, real_api: bool = True) -> Dict:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

        Args:
            scenarios: –°–ø–∏—Å–æ–∫ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            models: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            real_api: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ API –≤—ã–∑–æ–≤—ã

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if scenarios is None:
            scenarios = self.create_test_scenarios(use_real_files=real_api)

        if not scenarios:
            raise ValueError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if models is None:
            models = self.openai_models.copy()
            if self.replicate_available:
                models.append("replicate-whisper-diarization")
        else:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –º–æ–¥–µ–ª–∏
            filtered_models = []
            for model in models:
                if model == "replicate":
                    if self.replicate_available:
                        filtered_models.append("replicate-whisper-diarization")
                elif model in self.openai_models:
                    filtered_models.append(model)
            models = filtered_models

        self.logger.info(f"üß™ –ù–∞—á–∏–Ω–∞—é –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(scenarios)} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤...")
        self.logger.info(f"ü§ñ –ú–æ–¥–µ–ª–∏: {', '.join(models)}")

        all_results = {
            "test_summary": {
                "total_scenarios": len(scenarios),
                "total_models": len(models),
                "start_time": time.time(),
                "test_type": "real_api" if real_api else "demo",
                "models_tested": models
            },
            "scenarios": {},
            "model_comparison": {}
        }

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π
        for scenario in scenarios:
            self.logger.info(f"üìã –¢–µ—Å—Ç–∏—Ä—É—é —Å—Ü–µ–Ω–∞—Ä–∏–π: {scenario.name}")

            scenario_results = {
                "scenario_info": {
                    "name": scenario.name,
                    "description": scenario.description,
                    "audio_file": str(scenario.audio_file),
                    "language": scenario.language,
                    "reference_text": scenario.reference_text
                },
                "model_results": {}
            }

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º OpenAI –º–æ–¥–µ–ª–∏
            for model in [m for m in models if m in self.openai_models]:
                result = self.test_openai_model(model, scenario)
                evaluation = self.evaluator.evaluate_transcription(scenario.reference_text, result)
                scenario_results["model_results"][model] = evaluation

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º Replicate –º–æ–¥–µ–ª—å
            if "replicate-whisper-diarization" in models and self.replicate_available:
                result = self.test_replicate_model(scenario)
                if result:
                    evaluation = self.evaluator.evaluate_transcription(scenario.reference_text, result)
                    scenario_results["model_results"]["replicate-whisper-diarization"] = evaluation

            all_results["scenarios"][scenario.name] = scenario_results

        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ –º–æ–¥–µ–ª—è–º
        all_results["model_comparison"] = self._create_model_comparison(all_results["scenarios"])
        all_results["test_summary"]["end_time"] = time.time()
        all_results["test_summary"]["total_duration"] = all_results["test_summary"]["end_time"] - all_results["test_summary"]["start_time"]

        return all_results

    def _create_model_comparison(self, scenarios_results: Dict) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –º–æ–¥–µ–ª–µ–π"""
        model_stats = {}

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for scenario_name, scenario_data in scenarios_results.items():
            for model_name, model_result in scenario_data["model_results"].items():
                if model_name not in model_stats:
                    model_stats[model_name] = {
                        "total_tests": 0,
                        "successful_tests": 0,
                        "total_wer": 0.0,
                        "total_cer": 0.0,
                        "total_processing_time": 0.0,
                        "costs": []
                    }

                stats = model_stats[model_name]
                stats["total_tests"] += 1

                if model_result.get("success", False):
                    stats["successful_tests"] += 1
                    quality_metrics = model_result.get("quality_metrics", {})
                    stats["total_wer"] += quality_metrics.get("wer", 1.0)
                    stats["total_cer"] += quality_metrics.get("cer", 1.0)
                    stats["total_processing_time"] += model_result.get("processing_time", 0.0)

                    # –ü–∞—Ä—Å–∏–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
                    cost_str = model_result.get("estimated_cost", "N/A")
                    if cost_str.startswith("~$"):
                        try:
                            cost_value = float(cost_str.replace("~$", ""))
                            stats["costs"].append(cost_value)
                        except ValueError:
                            pass

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        comparison = {}
        for model_name, stats in model_stats.items():
            successful_tests = stats["successful_tests"]

            if successful_tests > 0:
                avg_wer = stats["total_wer"] / successful_tests
                avg_cer = stats["total_cer"] / successful_tests
                avg_processing_time = stats["total_processing_time"] / successful_tests
                avg_cost = sum(stats["costs"]) / len(stats["costs"]) if stats["costs"] else 0.0

                comparison[model_name] = {
                    "success_rate": successful_tests / stats["total_tests"],
                    "average_wer": round(avg_wer, 4),
                    "average_cer": round(avg_cer, 4),
                    "word_accuracy": round(1.0 - avg_wer, 4),
                    "char_accuracy": round(1.0 - avg_cer, 4),
                    "average_processing_time": round(avg_processing_time, 2),
                    "average_cost_usd": round(avg_cost, 4),
                    "total_tests": stats["total_tests"],
                    "successful_tests": successful_tests
                }
            else:
                comparison[model_name] = {
                    "success_rate": 0.0,
                    "average_wer": 1.0,
                    "average_cer": 1.0,
                    "word_accuracy": 0.0,
                    "char_accuracy": 0.0,
                    "average_processing_time": 0.0,
                    "average_cost_usd": 0.0,
                    "total_tests": stats["total_tests"],
                    "successful_tests": 0,
                    "note": "–í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –æ—à–∏–±–∫–æ–π"
                }

        return comparison

    def generate_report(self, results: Dict, output_dir: Path = None) -> Path:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        if output_dir is None:
            output_dir = Path("data/interim")

        output_dir.mkdir(parents=True, exist_ok=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        test_type = results["test_summary"].get("test_type", "unknown")
        json_path = output_dir / f"{test_type}_quality_evaluation_results.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        report_path = output_dir / f"{test_type}_quality_evaluation_report.md"
        self._generate_markdown_report(results, report_path)

        self.logger.info(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        return report_path

    def _generate_markdown_report(self, results: Dict, output_path: Path) -> None:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –æ—Ç—á–µ—Ç"""
        with open(output_path, 'w', encoding='utf-8') as f:
            test_type = results["test_summary"].get("test_type", "unknown")
            f.write(f"# –û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ ({test_type})\n\n")

            # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            summary = results["test_summary"]
            f.write(f"**–î–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**–¢–∏–ø —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {test_type}\n")
            f.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤:** {summary['total_scenarios']}\n")
            f.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π:** {summary['total_models']}\n")
            f.write(f"**–û–±—â–µ–µ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {summary['total_duration']:.2f} —Å–µ–∫—É–Ω–¥\n")
            f.write(f"**–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:** {', '.join(summary.get('models_tested', []))}\n\n")

            # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
            f.write("## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n\n")
            f.write("| –ú–æ–¥–µ–ª—å | –¢–æ—á–Ω–æ—Å—Ç—å —Å–ª–æ–≤ | –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–º–≤–æ–ª–æ–≤ | WER | CER | –í—Ä–µ–º—è (—Å) | –°—Ç–æ–∏–º–æ—Å—Ç—å ($) | –£—Å–ø–µ—à–Ω–æ—Å—Ç—å |\n")
            f.write("|--------|---------------|-------------------|-----|-----|-----------|---------------|------------|\n")

            comparison = results["model_comparison"]
            for model_name, stats in sorted(comparison.items(), key=lambda x: x[1]["word_accuracy"], reverse=True):
                f.write(f"| {model_name} | {stats['word_accuracy']:.3f} | {stats['char_accuracy']:.3f} | "
                       f"{stats['average_wer']:.3f} | {stats['average_cer']:.3f} | "
                       f"{stats['average_processing_time']:.2f} | {stats['average_cost_usd']:.4f} | "
                       f"{stats['success_rate']:.1%} |\n")

            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if comparison:
                f.write("\n## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
                best_accuracy = max(comparison.values(), key=lambda x: x["word_accuracy"])
                fastest = min([v for v in comparison.values() if v["success_rate"] > 0], key=lambda x: x["average_processing_time"])
                cheapest = min([v for v in comparison.values() if v["success_rate"] > 0], key=lambda x: x["average_cost_usd"])

                best_model = [k for k, v in comparison.items() if v == best_accuracy][0]
                fastest_model = [k for k, v in comparison.items() if v == fastest][0]
                cheapest_model = [k for k, v in comparison.items() if v == cheapest][0]

                f.write(f"- **–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:** {best_model} (—Ç–æ—á–Ω–æ—Å—Ç—å —Å–ª–æ–≤: {best_accuracy['word_accuracy']:.3f})\n")
                f.write(f"- **–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è:** {fastest_model} (–≤—Ä–µ–º—è: {fastest['average_processing_time']:.2f}—Å)\n")
                f.write(f"- **–°–∞–º–∞—è —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è:** {cheapest_model} (—Å—Ç–æ–∏–º–æ—Å—Ç—å: ${cheapest['average_cost_usd']:.4f})\n")

            # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Å—Ü–µ–Ω–∞—Ä–∏—è–º
            f.write("\n## –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n\n")
            for scenario_name, scenario_data in results["scenarios"].items():
                f.write(f"### {scenario_name}\n\n")
                f.write(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {scenario_data['scenario_info']['description']}\n")
                language = scenario_data['scenario_info'].get('language', '–ù–µ —É–∫–∞–∑–∞–Ω')
                f.write(f"**–Ø–∑—ã–∫:** {language}\n")
                f.write(f"**–§–∞–π–ª:** {scenario_data['scenario_info']['audio_file']}\n")
                f.write(f"**–≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:** {scenario_data['scenario_info']['reference_text'][:100]}...\n\n")

                for model_name, result in scenario_data["model_results"].items():
                    if result.get("success", False):
                        metrics = result["quality_metrics"]
                        f.write(f"- **{model_name}:** WER={metrics['wer']:.3f}, "
                               f"CER={metrics['cer']:.3f}, "
                               f"–≤—Ä–µ–º—è={result['processing_time']:.2f}—Å, "
                               f"—Å—Ç–æ–∏–º–æ—Å—Ç—å={result['estimated_cost']}\n")
                    else:
                        f.write(f"- **{model_name}:** ‚ùå –û—à–∏–±–∫–∞ - {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}\n")

                f.write("\n")


def setup_logging(verbose: bool = False) -> None:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    level = logging.DEBUG if verbose else logging.INFO

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
    Path('logs').mkdir(exist_ok=True)

    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('logs/quality_testing_suite.log', encoding='utf-8')
        ]
    )

    # –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤—ã–≤–æ–¥–∞
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('requests').setLevel(logging.WARNING)
    logging.getLogger('openai').setLevel(logging.WARNING)


def validate_api_keys() -> tuple:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å API –∫–ª—é—á–µ–π"""
    openai_key = os.getenv('OPENAI_API_KEY')
    replicate_key = os.getenv('REPLICATE_API_TOKEN')

    if not openai_key:
        print("‚ùå –û—à–∏–±–∫–∞: OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–ª—é—á: export OPENAI_API_KEY='your-key-here'")
        sys.exit(1)

    if not replicate_key:
        print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: REPLICATE_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("Replicate –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–∞")

    print(f"‚úÖ OpenAI API –∫–ª—é—á: {openai_key[:10]}...")
    if replicate_key:
        print(f"‚úÖ Replicate API –∫–ª—é—á: {replicate_key[:10]}...")

    return openai_key, replicate_key


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    parser = argparse.ArgumentParser(
        description="Quality Testing Suite - –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

1. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö API –≤—ã–∑–æ–≤–æ–≤):
   python quality_testing_suite.py --demo

2. –†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏:
   python quality_testing_suite.py --real

3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:
   python quality_testing_suite.py --audio-files audio1.wav audio2.mp3

4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏:
   python quality_testing_suite.py --audio-files audio.wav --reference-texts "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä"

5. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:
   python quality_testing_suite.py --models whisper-1 gpt-4o-transcribe

6. –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥:
   python quality_testing_suite.py --verbose

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
- OPENAI_API_KEY: –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª—é—á OpenAI API
- REPLICATE_API_TOKEN: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω Replicate API
        """
    )

    # –†–µ–∂–∏–º—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        '--demo',
        action='store_true',
        help='–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–æ–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏'
    )
    mode_group.add_argument(
        '--real',
        action='store_true',
        help='–†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –Ω–∞—Å—Ç–æ—è—â–∏–º–∏ API –≤—ã–∑–æ–≤–∞–º–∏'
    )

    # –§–∞–π–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    parser.add_argument(
        '--audio-files',
        nargs='+',
        help='–°–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è'
    )

    parser.add_argument(
        '--reference-texts',
        nargs='+',
        help='–≠—Ç–∞–ª–æ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ (–≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ)'
    )

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    parser.add_argument(
        '--models',
        nargs='+',
        choices=['whisper-1', 'gpt-4o-mini-transcribe', 'gpt-4o-transcribe', 'replicate'],
        help='–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ)'
    )

    parser.add_argument(
        '--output-dir',
        type=Path,
        default=Path('data/interim'),
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: data/interim)'
    )

    parser.add_argument(
        '--language',
        help='–ö–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: en, ru, de)'
    )

    parser.add_argument(
        '--verbose',
        action='store_true',
        help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ª–æ–≥–æ–≤'
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='–ü–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è'
    )

    args = parser.parse_args()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)

    print("üß™ Quality Testing Suite - –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    print("=" * 70)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if args.demo:
        test_mode = "demo"
        print("üé≠ –†–µ–∂–∏–º: –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)")
        real_api = False
    elif args.real:
        test_mode = "real"
        print("üî• –†–µ–∂–∏–º: –†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–Ω–∞—Å—Ç–æ—è—â–∏–µ API –≤—ã–∑–æ–≤—ã)")
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è –∏ —Å—Ç–æ–∏—Ç—å –¥–µ–Ω–µ–≥!")
        real_api = True
    elif args.audio_files:
        test_mode = "custom"
        print("üìÅ –†–µ–∂–∏–º: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ñ–∞–π–ª—ã")
        real_api = True
    else:
        test_mode = "auto"
        print("ü§ñ –†–µ–∂–∏–º: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (—Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)")
        real_api = True

    # –ó–∞–≥—Ä—É–∂–∞–µ–º API –∫–ª—é—á–∏
    openai_key, replicate_key = validate_api_keys()

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–µ—Ä
    suite = QualityTestingSuite(
        openai_api_key=openai_key,
        replicate_api_key=replicate_key
    )

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
    if args.audio_files:
        scenarios = suite.create_test_scenarios(
            audio_files=args.audio_files,
            reference_texts=args.reference_texts,
            use_real_files=False
        )
    else:
        scenarios = suite.create_test_scenarios(use_real_files=real_api)

    if not scenarios:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏")
        if test_mode == "real":
            print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∞—á–∞–ª–∞: python3 create_accurate_references.py")
        sys.exit(1)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    print(f"\nüìã –ü–ª–∞–Ω —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"–°—Ü–µ–Ω–∞—Ä–∏–µ–≤: {len(scenarios)}")
    for scenario in scenarios:
        print(f"  - {scenario.name}: {scenario.description}")
        if args.verbose:
            print(f"    –§–∞–π–ª: {scenario.audio_file}")
            print(f"    –†–∞–∑–º–µ—Ä: {scenario.audio_file.stat().st_size / (1024*1024):.2f} MB")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏
    available_models = suite.openai_models.copy()
    if suite.replicate_available:
        available_models.append("replicate-whisper-diarization")

    if args.models:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –º–æ–¥–µ–ª–∏
        filtered_models = []
        for model in args.models:
            if model == "replicate":
                if suite.replicate_available:
                    filtered_models.append("replicate-whisper-diarization")
            elif model in suite.openai_models:
                filtered_models.append(model)
        available_models = filtered_models

    print(f"–ú–æ–¥–µ–ª–∏: {', '.join(available_models)}")
    print(f"–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {args.output_dir}")

    if args.dry_run:
        print("\nüîç –†–µ–∂–∏–º dry-run: –ø–ª–∞–Ω –ø–æ–∫–∞–∑–∞–Ω, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è")
        return

    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    if real_api and test_mode in ["real", "auto"]:
        confirm = input("\n‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ? (y/N): ")
        if confirm.lower() != 'y':
            print("‚ùå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            sys.exit(0)

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    try:
        results = suite.run_comprehensive_test(
            scenarios=scenarios,
            models=available_models,
            real_api=real_api
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        print(f"\nüìä –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç...")
        report_path = suite.generate_report(results, args.output_dir)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –º–æ–¥–µ–ª–∏ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
        comparison = results["model_comparison"]
        if comparison:
            print(f"\nüèÜ –¢–æ–ø-3 –º–æ–¥–µ–ª–∏ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤:")
            sorted_models = sorted(comparison.items(), key=lambda x: x[1]["word_accuracy"], reverse=True)
            for i, (model_name, stats) in enumerate(sorted_models[:3], 1):
                print(f"  {i}. {model_name}: {stats['word_accuracy']:.3f} (WER: {stats['average_wer']:.3f})")

    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
