# pipeline/export_agent.py

import datetime as _dt
import json
import logging
import time
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from .base_agent import BaseAgent
from .validation_mixin import ValidationMixin


@dataclass
class ExportMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
    total_segments: int
    total_duration: float
    speakers_count: int
    total_words: int
    average_segment_duration: float
    export_formats: List[str]
    file_sizes: Dict[str, int]


class ExportAgent(BaseAgent, ValidationMixin):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
    - SRT: SubRip —Å—É–±—Ç–∏—Ç—Ä—ã
    - JSON: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    - ASS: Advanced SubStation Alpha
    - VTT: WebVTT —Å—É–±—Ç–∏—Ç—Ä—ã
    - TTML: Timed Text Markup Language
    - TXT: –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    - CSV: –¢–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    - DOCX: Microsoft Word –¥–æ–∫—É–º–µ–Ω—Ç
    """

    SUPPORTED_FORMATS = ["srt", "json", "ass", "vtt", "ttml", "txt", "csv", "docx"]

    def __init__(self, format: str = "srt", create_all_formats: bool = False,
                 overwrite_existing: bool = False, add_timestamp: bool = False,
                 include_confidence: bool = False, speaker_colors: bool = True):
        """
        Args:
            format: –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞
            create_all_formats: –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª—ã –≤–æ –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            overwrite_existing: –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
            add_timestamp: –î–æ–±–∞–≤–ª—è—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –∫ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
            include_confidence: –í–∫–ª—é—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            speaker_colors: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ü–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–ø–∏–∫–µ—Ä–æ–≤
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        BaseAgent.__init__(self, name="ExportAgent")
        ValidationMixin.__init__(self)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥
        self.validate_export_format(format)

        self.format = format
        self.create_all_formats = create_all_formats
        self.overwrite_existing = overwrite_existing
        self.add_timestamp = add_timestamp
        self.include_confidence = include_confidence
        self.speaker_colors = speaker_colors

        # –¶–≤–µ—Ç–∞ –¥–ª—è —Å–ø–∏–∫–µ—Ä–æ–≤ (–¥–ª—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏—Ö —Ü–≤–µ—Ç–∞)
        self.speaker_color_map = {
            "SPEAKER_00": "#FF6B6B",  # –ö—Ä–∞—Å–Ω—ã–π
            "SPEAKER_01": "#4ECDC4",  # –ë–∏—Ä—é–∑–æ–≤—ã–π
            "SPEAKER_02": "#45B7D1",  # –°–∏–Ω–∏–π
            "SPEAKER_03": "#96CEB4",  # –ó–µ–ª–µ–Ω—ã–π
            "SPEAKER_04": "#FFEAA7",  # –ñ–µ–ª—Ç—ã–π
            "SPEAKER_05": "#DDA0DD",  # –§–∏–æ–ª–µ—Ç–æ–≤—ã–π
            "SPEAKER_06": "#98D8C8",  # –ú—è—Ç–Ω—ã–π
            "SPEAKER_07": "#F7DC6F",  # –ó–æ–ª–æ—Ç–æ–π
        }

        self.log_with_emoji("info", "üì§", f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —Ñ–æ—Ä–º–∞—Ç–æ–º: {format}")
        if create_all_formats:
            self.log_with_emoji("info", "üìã", f"–ë—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(self.SUPPORTED_FORMATS)}")

    def validate_export_format(self, format: str) -> None:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞.

        Args:
            format: –§–æ—Ä–º–∞—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        Raises:
            ValueError: –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        """
        if not isinstance(format, str):
            raise ValueError(f"–§–æ—Ä–º–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –ø–æ–ª—É—á–µ–Ω {type(format)}")

        format = format.lower().strip()

        if not format:
            raise ValueError("–§–æ—Ä–º–∞—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

        if format not in self.SUPPORTED_FORMATS:
            raise ValueError(
                f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}. "
                f"–î–æ—Å—Ç—É–ø–Ω—ã–µ: {', '.join(self.SUPPORTED_FORMATS)}"
            )

    def validate_export_segments(self, segments: List[Dict]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.

        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        """
        issues = []

        if not isinstance(segments, list):
            issues.append("–°–µ–≥–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")
            return issues

        if not segments:
            issues.append("–°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç")
            return issues

        required_fields = ["start", "end", "speaker", "text"]

        for i, segment in enumerate(segments):
            if not isinstance(segment, dict):
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º")
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            for field in required_fields:
                if field not in segment:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ '{field}'")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
            if "start" in segment and not isinstance(segment["start"], (int, float)):
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: 'start' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")

            if "end" in segment and not isinstance(segment["end"], (int, float)):
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: 'end' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ–º")

            if "speaker" in segment and not isinstance(segment["speaker"], str):
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: 'speaker' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")

            if "text" in segment and not isinstance(segment["text"], str):
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: 'text' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            if ("start" in segment and "end" in segment and
                isinstance(segment["start"], (int, float)) and
                isinstance(segment["end"], (int, float))):

                if segment["start"] < 0:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞")

                if segment["end"] < 0:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è")

                if segment["start"] >= segment["end"]:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏")

        return issues

    def validate_output_path(self, output_path: Path) -> None:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—É—Ç–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.

        Args:
            output_path: –ü—É—Ç—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        Raises:
            ValueError: –ï—Å–ª–∏ –ø—É—Ç—å –Ω–µ–≤–∞–ª–∏–¥–µ–Ω
        """
        if not isinstance(output_path, Path):
            raise ValueError(f"output_path –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å Path –æ–±—ä–µ–∫—Ç–æ–º, –ø–æ–ª—É—á–µ–Ω {type(output_path)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞
        parent_dir = output_path.parent
        if not parent_dir.exists():
            try:
                parent_dir.mkdir(parents=True, exist_ok=True)
                self.log_with_emoji("info", "üìÅ", f"–°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {parent_dir}")
            except Exception as e:
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é {parent_dir}: {e}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å
        if parent_dir.exists() and not parent_dir.is_dir():
            raise ValueError(f"–†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –ø—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {parent_dir}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π
        if output_path.exists() and output_path.is_dir():
            raise ValueError(f"–ü—É—Ç—å —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –∞ –Ω–µ –Ω–∞ —Ñ–∞–π–ª: {output_path}")

    def get_speaker_color(self, speaker: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–≤–µ—Ç –¥–ª—è —Å–ø–∏–∫–µ—Ä–∞"""
        if not self.speaker_colors:
            return "#FFFFFF"  # –ë–µ–ª—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        return self.speaker_color_map.get(speaker, "#CCCCCC")  # –°–µ—Ä—ã–π –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö

    def _ts_srt(self, sec: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è SRT"""
        td = _dt.timedelta(seconds=sec)
        h, r = divmod(td.seconds, 3600)
        m, s = divmod(r, 60)
        ms = int(td.microseconds / 1000)
        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    def _ts_ass(self, sec: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è ASS"""
        td = _dt.timedelta(seconds=sec)
        h, r = divmod(td.seconds, 3600)
        m, s = divmod(r, 60)
        cs = int(td.microseconds / 10_000)  # centiseconds
        return f"{h:d}:{m:02}:{s:02}.{cs:02}"

    def _ts_vtt(self, sec: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è VTT"""
        td = _dt.timedelta(seconds=sec)
        h, r = divmod(td.seconds, 3600)
        m, s = divmod(r, 60)
        ms = int(td.microseconds / 1000)
        return f"{h:02}:{m:02}:{s:02}.{ms:03}"

    def _ts_ttml(self, sec: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è TTML"""
        return f"{sec:.3f}s"

    def write_srt(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ SRT —Ñ–æ—Ä–º–∞—Ç"""
        with open(outfile, "w", encoding="utf-8") as f:
            for idx, s in enumerate(segs, 1):
                f.write(f"{idx}\n{self._ts_srt(s['start'])} --> {self._ts_srt(s['end'])}\n")

                # –î–æ–±–∞–≤–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                confidence_info = ""
                if self.include_confidence and 'confidence' in s:
                    confidence_info = f" [{s['confidence']:.2f}]"

                f.write(f"{s['speaker']}: {s['text']}{confidence_info}\n\n")

    def write_json(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç"""
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        export_data = {
            "metadata": {
                "export_timestamp": _dt.datetime.now().isoformat(),
                "total_segments": len(segs),
                "total_duration": max(s['end'] for s in segs) if segs else 0,
                "speakers": list(set(s['speaker'] for s in segs)),
                "include_confidence": self.include_confidence
            },
            "segments": segs
        }

        outfile.write_text(json.dumps(export_data, indent=2, ensure_ascii=False))

    def write_ass(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ ASS —Ñ–æ—Ä–º–∞—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ü–≤–µ—Ç–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∏–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
        speakers = list(set(s['speaker'] for s in segs))
        styles = []

        for speaker in speakers:
            color = self.get_speaker_color(speaker)
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º hex –≤ BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è ASS
            color_bgr = f"&H00{color[5:7]}{color[3:5]}{color[1:3]}"

            styles.append(
                f"Style: {speaker},Arial,24,{color_bgr},&H000000FF,&H00000000,&H64000000,"
                f"-1,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1"
            )

        header = (
            "[Script Info]\n"
            "Title: speech_pipeline export\n"
            "ScriptType: v4.00+\n"
            "Collisions: Normal\n"
            "PlayResX: 384\n"
            "PlayResY: 288\n"
            "[V4+ Styles]\n"
            "Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,"
            "Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,"
            "Alignment,MarginL,MarginR,MarginV,Encoding\n"
        )

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∏–ª–∏
        header += "\n".join(styles) + "\n"

        header += (
            "[Events]\n"
            "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"
        )

        with open(outfile, "w", encoding="utf-8") as f:
            f.write(header)
            for s in segs:
                style = s['speaker'] if s['speaker'] in speakers else "Default"
                confidence_info = ""
                if self.include_confidence and 'confidence' in s:
                    confidence_info = f" [{s['confidence']:.2f}]"

                f.write(
                    f"Dialogue: 0,{self._ts_ass(s['start'])},{self._ts_ass(s['end'])},"
                    f"{style},{s['speaker']},0,0,0,,{s['text']}{confidence_info}\n"
                )

    def write_vtt(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ WebVTT —Ñ–æ—Ä–º–∞—Ç"""
        with open(outfile, "w", encoding="utf-8") as f:
            f.write("WEBVTT\n\n")

            for idx, s in enumerate(segs, 1):
                # WebVTT –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ü–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ CSS
                color = self.get_speaker_color(s['speaker']) if self.speaker_colors else None

                f.write(f"{idx}\n")
                f.write(f"{self._ts_vtt(s['start'])} --> {self._ts_vtt(s['end'])}\n")

                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∏–ª—å –µ—Å–ª–∏ –Ω—É–∂–µ–Ω —Ü–≤–µ—Ç
                text = s['text']
                if color and self.speaker_colors:
                    text = f"<c.{s['speaker'].lower()}>{text}</c>"

                confidence_info = ""
                if self.include_confidence and 'confidence' in s:
                    confidence_info = f" [{s['confidence']:.2f}]"

                f.write(f"{s['speaker']}: {text}{confidence_info}\n\n")

    def write_ttml(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ TTML —Ñ–æ—Ä–º–∞—Ç"""
        # –°–æ–∑–¥–∞–µ–º XML —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        root = ET.Element("tt")
        root.set("xmlns", "http://www.w3.org/ns/ttml")
        root.set("xmlns:tts", "http://www.w3.org/ns/ttml#styling")

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        head = ET.SubElement(root, "head")
        styling = ET.SubElement(head, "styling")

        # –°—Ç–∏–ª–∏ –¥–ª—è —Å–ø–∏–∫–µ—Ä–æ–≤
        speakers = list(set(s['speaker'] for s in segs))
        for speaker in speakers:
            style = ET.SubElement(styling, "style")
            style.set("xml:id", speaker.lower())
            if self.speaker_colors:
                style.set("tts:color", self.get_speaker_color(speaker))

        # –¢–µ–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        body = ET.SubElement(root, "body")
        div = ET.SubElement(body, "div")

        for s in segs:
            p = ET.SubElement(div, "p")
            p.set("begin", self._ts_ttml(s['start']))
            p.set("end", self._ts_ttml(s['end']))
            p.set("style", s['speaker'].lower())

            confidence_info = ""
            if self.include_confidence and 'confidence' in s:
                confidence_info = f" [{s['confidence']:.2f}]"

            p.text = f"{s['speaker']}: {s['text']}{confidence_info}"

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º XML
        tree = ET.ElementTree(root)
        tree.write(outfile, encoding="utf-8", xml_declaration=True)

    def write_txt(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        with open(outfile, "w", encoding="utf-8") as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            f.write("–¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø –ê–£–î–ò–û\n")
            f.write("=" * 50 + "\n")
            f.write(f"–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {_dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segs)}\n")
            if segs:
                f.write(f"–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {max(s['end'] for s in segs):.2f} —Å–µ–∫—É–Ω–¥\n")
            f.write("=" * 50 + "\n\n")

            current_speaker = None
            for s in segs:
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                if s['speaker'] != current_speaker:
                    if current_speaker is not None:
                        f.write("\n")
                    f.write(f"[{s['speaker']}]\n")
                    current_speaker = s['speaker']

                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                start_time = f"{int(s['start']//60):02d}:{int(s['start']%60):02d}"
                end_time = f"{int(s['end']//60):02d}:{int(s['end']%60):02d}"

                confidence_info = ""
                if self.include_confidence and 'confidence' in s:
                    confidence_info = f" (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {s['confidence']:.2f})"

                f.write(f"[{start_time}-{end_time}]{confidence_info} {s['text']}\n")

    def write_csv(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV —Ñ–æ—Ä–º–∞—Ç"""
        import csv

        with open(outfile, "w", encoding="utf-8", newline='') as f:
            fieldnames = ['start_time', 'end_time', 'duration', 'speaker', 'text']
            if self.include_confidence:
                fieldnames.append('confidence')

            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for s in segs:
                row = {
                    'start_time': f"{s['start']:.3f}",
                    'end_time': f"{s['end']:.3f}",
                    'duration': f"{s['end'] - s['start']:.3f}",
                    'speaker': s['speaker'],
                    'text': s['text']
                }

                if self.include_confidence and 'confidence' in s:
                    row['confidence'] = f"{s['confidence']:.3f}"

                writer.writerow(row)

    def write_docx(self, segs: List[Dict], outfile: Path):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ DOCX —Ñ–æ—Ä–º–∞—Ç"""
        try:
            from docx import Document
            from docx.shared import RGBColor
        except ImportError:
            self.log_with_emoji("error", "‚ùå", "–î–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ DOCX —Ç—Ä–µ–±—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-docx")
            self.log_with_emoji("info", "üí°", "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
            raise ImportError("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        doc = Document()

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title = doc.add_heading('–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ', 0)

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        meta_para = doc.add_paragraph()
        meta_para.add_run(f"–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {_dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        meta_para.add_run(f"–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segs)}\n")
        if segs:
            meta_para.add_run(f"–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {max(s['end'] for s in segs):.2f} —Å–µ–∫—É–Ω–¥\n")

        doc.add_paragraph()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        current_speaker = None
        for s in segs:
            if s['speaker'] != current_speaker:
                # –ù–æ–≤—ã–π —Å–ø–∏–∫–µ—Ä - –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                speaker_heading = doc.add_heading(f"–°–ø–∏–∫–µ—Ä: {s['speaker']}", level=2)
                current_speaker = s['speaker']

            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
            para = doc.add_paragraph()

            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            start_time = f"{int(s['start']//60):02d}:{int(s['start']%60):02d}"
            end_time = f"{int(s['end']//60):02d}:{int(s['end']%60):02d}"

            time_run = para.add_run(f"[{start_time}-{end_time}] ")
            time_run.bold = True

            # –¢–µ–∫—Å—Ç
            text_run = para.add_run(s['text'])

            # –¶–≤–µ—Ç –¥–ª—è —Å–ø–∏–∫–µ—Ä–∞ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
            if self.speaker_colors:
                color_hex = self.get_speaker_color(s['speaker'])
                rgb = tuple(int(color_hex[i:i+2], 16) for i in (1, 3, 5))
                text_run.font.color.rgb = RGBColor(*rgb)

            # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            if self.include_confidence and 'confidence' in s:
                conf_run = para.add_run(f" (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {s['confidence']:.2f})")
                conf_run.italic = True

        doc.save(outfile)

    def _generate_unique_filename(self, output_path: Path, format: str) -> Path:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
        corrected_path = self._ensure_correct_extension(output_path, format)

        if self.overwrite_existing:
            return corrected_path

        if not corrected_path.exists():
            return corrected_path

        base_path = corrected_path.with_suffix('')
        extension = corrected_path.suffix

        if self.add_timestamp:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            unique_path = Path(f"{base_path}_{timestamp}{extension}")

            counter = 1
            while unique_path.exists():
                unique_path = Path(f"{base_path}_{timestamp}_{counter:03d}{extension}")
                counter += 1
        else:
            counter = 1
            unique_path = Path(f"{base_path}_{counter:03d}{extension}")
            while unique_path.exists():
                counter += 1
                unique_path = Path(f"{base_path}_{counter:03d}{extension}")

        self.logger.info(f"üìù –§–∞–π–ª {corrected_path} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞—é —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è: {unique_path}")
        return unique_path



    def _export_single_format(self, merged: List[Dict], output_path: Path, format: str):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –æ–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        export_methods = {
            "srt": self.write_srt,
            "json": self.write_json,
            "ass": self.write_ass,
            "vtt": self.write_vtt,
            "ttml": self.write_ttml,
            "txt": self.write_txt,
            "csv": self.write_csv,
            "docx": self.write_docx
        }

        if format not in export_methods:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")

        try:
            export_methods[format](merged, output_path)
            self.log_with_emoji("info", "‚úÖ", f"–≠–∫—Å–ø–æ—Ä—Ç –≤ {format.upper()} –∑–∞–≤–µ—Ä—à–µ–Ω: {output_path}")
        except Exception as e:
            self.log_with_emoji("error", "‚ùå", f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ {format.upper()}: {e}")
            raise

    def calculate_export_metrics(self, merged: List[Dict], created_files: List[Path]) -> ExportMetrics:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        if not merged:
            return ExportMetrics(
                total_segments=0, total_duration=0.0, speakers_count=0,
                total_words=0, average_segment_duration=0.0,
                export_formats=[], file_sizes={}
            )

        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        total_segments = len(merged)
        total_duration = max(s['end'] for s in merged) if merged else 0
        speakers = set(s['speaker'] for s in merged)
        speakers_count = len(speakers)

        # –ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤
        total_words = sum(len(s['text'].split()) for s in merged)

        # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞
        segment_durations = [s['end'] - s['start'] for s in merged]
        average_segment_duration = sum(segment_durations) / len(segment_durations)

        # –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
        file_sizes = {}
        export_formats = []

        for file_path in created_files:
            if file_path.exists():
                format_name = file_path.suffix[1:].upper()  # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫—É
                file_sizes[format_name] = file_path.stat().st_size
                export_formats.append(format_name)

        return ExportMetrics(
            total_segments=total_segments,
            total_duration=total_duration,
            speakers_count=speakers_count,
            total_words=total_words,
            average_segment_duration=average_segment_duration,
            export_formats=export_formats,
            file_sizes=file_sizes
        )

    def run(self, merged: List[Dict], output_path: Path) -> List[Path]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é

        Args:
            merged: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        self.start_operation("—ç–∫—Å–ø–æ—Ä—Ç")

        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            segment_issues = self.validate_export_segments(merged)
            if segment_issues:
                self.log_with_emoji("warning", "‚ö†Ô∏è", f"–ü—Ä–æ–±–ª–µ–º—ã –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö: {len(segment_issues)}")
                for issue in segment_issues[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    self.log_with_emoji("warning", "   ", issue)

                if not merged:  # –ï—Å–ª–∏ —Å–µ–≥–º–µ–Ω—Ç—ã –ø—É—Å—Ç—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º
                    self.end_operation("—ç–∫—Å–ø–æ—Ä—Ç", success=True)
                    return []

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—É—Ç–∏ –≤—ã–≤–æ–¥–∞
            self.validate_output_path(output_path)

            self.log_with_emoji("info", "üì§", f"–ù–∞—á–∏–Ω–∞—é —ç–∫—Å–ø–æ—Ä—Ç {len(merged)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")

            created_files = []

            if self.create_all_formats:
                # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –≤–æ –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
                base_path = output_path.with_suffix('')

                for fmt in self.SUPPORTED_FORMATS:
                    try:
                        fmt_path = self._generate_unique_filename(base_path, fmt)
                        self._export_single_format(merged, fmt_path, fmt)
                        created_files.append(fmt_path)
                    except Exception as e:
                        self.log_with_emoji("error", "‚ùå", f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ {fmt.upper()}: {e}")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –¥—Ä—É–≥–∏–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏

                self.log_with_emoji("info", "‚úÖ", f"–°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(created_files)} –∏–∑ {len(self.SUPPORTED_FORMATS)} —Ñ–æ—Ä–º–∞—Ç–æ–≤")
            else:
                # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Ç–æ–ª—å–∫–æ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                unique_path = self._generate_unique_filename(output_path, self.format)
                self._export_single_format(merged, unique_path, self.format)
                created_files.append(unique_path)

                self.log_with_emoji("info", "‚úÖ", f"–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ {self.format.upper()}: {unique_path}")

            # –í—ã—á–∏—Å–ª—è–µ–º –∏ –ª–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            if created_files:
                metrics = self.calculate_export_metrics(merged, created_files)
                self.log_with_emoji("info", "üìä", "–ú–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞:")
                self.log_with_emoji("info", "   ", f"–°–µ–≥–º–µ–Ω—Ç–æ–≤: {metrics.total_segments}")
                self.log_with_emoji("info", "   ", f"–°–ø–∏–∫–µ—Ä–æ–≤: {metrics.speakers_count}")
                self.log_with_emoji("info", "   ", f"–°–ª–æ–≤: {metrics.total_words}")
                self.log_with_emoji("info", "   ", f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {metrics.total_duration:.2f}—Å")

                # –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
                for fmt, size in metrics.file_sizes.items():
                    size_kb = size / 1024
                    self.log_with_emoji("info", "   ", f"{fmt}: {size_kb:.1f} KB")

            self.end_operation("—ç–∫—Å–ø–æ—Ä—Ç", success=True)
            return created_files

        except Exception as e:
            self.end_operation("—ç–∫—Å–ø–æ—Ä—Ç", success=False)
            self.handle_error(e, "—ç–∫—Å–ø–æ—Ä—Ç", reraise=True)

    def _ts_srt(self, sec: float) -> str:
        td = _dt.timedelta(seconds=sec)
        h, r = divmod(td.seconds, 3600)
        m, s = divmod(r, 60)
        ms = int(td.microseconds / 1000)
        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    def _ts_ass(self, sec: float) -> str:
        td = _dt.timedelta(seconds=sec)
        h, r = divmod(td.seconds, 3600)
        m, s = divmod(r, 60)
        cs = int(td.microseconds / 10_000)  # centiseconds
        return f"{h:d}:{m:02}:{s:02}.{cs:02}"

    def _generate_unique_filename(self, output_path: Path, format: str) -> Path:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –∏–∑–±–µ–≥–∞—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤.
        –î–æ–±–∞–≤–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –∏–ª–∏ —á–∏—Å–ª–æ–≤–æ–π —Å—É—Ñ—Ñ–∏–∫—Å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
        """
        corrected_path = self._ensure_correct_extension(output_path, format)

        # –ï—Å–ª–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å
        if self.overwrite_existing:
            return corrected_path

        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å
        if not corrected_path.exists():
            return corrected_path

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è
        base_path = corrected_path.with_suffix('')
        extension = corrected_path.suffix

        if self.add_timestamp:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            unique_path = Path(f"{base_path}_{timestamp}{extension}")

            # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π —Ç–æ–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫
            counter = 1
            while unique_path.exists():
                unique_path = Path(f"{base_path}_{timestamp}_{counter:03d}{extension}")
                counter += 1
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤–æ–π —Å—É—Ñ—Ñ–∏–∫—Å
            counter = 1
            unique_path = Path(f"{base_path}_{counter:03d}{extension}")
            while unique_path.exists():
                counter += 1
                unique_path = Path(f"{base_path}_{counter:03d}{extension}")

        self.log_with_emoji("info", "üìù", f"–§–∞–π–ª {corrected_path} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞—é —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è: {unique_path}")
        return unique_path

    def _ensure_correct_extension(self, output_path: Path, format: str) -> Path:
        """
        –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞.
        –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å.
        –ï—Å–ª–∏ –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ.
        """
        format_extensions = {
            "srt": ".srt",
            "json": ".json",
            "ass": ".ass",
            "vtt": ".vtt",
            "ttml": ".ttml",
            "txt": ".txt",
            "csv": ".csv",
            "docx": ".docx"
        }

        if format not in format_extensions:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")

        expected_ext = format_extensions[format]

        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if output_path.suffix.lower() == expected_ext:
            return output_path

        # –ï—Å–ª–∏ —Ñ–∞–π–ª –∏–º–µ–µ—Ç –¥—Ä—É–≥–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–ª–∏ –Ω–µ –∏–º–µ–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        if output_path.suffix:
            # –ó–∞–º–µ–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            return output_path.with_suffix(expected_ext)
        else:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫ —Ñ–∞–π–ª—É –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            return Path(str(output_path) + expected_ext)

    def write_json(self, segs: List[Dict], outfile: Path):
        outfile.write_text(json.dumps(segs, indent=2, ensure_ascii=False))

    def write_srt(self, segs: List[Dict], outfile: Path):
        with open(outfile, "w", encoding="utf-8") as f:
            for idx, s in enumerate(segs, 1):
                f.write(f"{idx}\n{self._ts_srt(s['start'])} --> {self._ts_srt(s['end'])}\n")
                f.write(f"{s['speaker']}: {s['text']}\n\n")

    def write_ass(self, segs: List[Dict], outfile: Path):
        header = (
            "[Script Info]\n"
            "Title: speech_pipeline export\n"
            "ScriptType: v4.00+\n"
            "Collisions: Normal\n"
            "PlayResX: 384\n"
            "PlayResY: 288\n"
            "[V4+ Styles]\n"
            "Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,"
            "Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,"
            "Alignment,MarginL,MarginR,MarginV,Encoding\n"
            "Style: Default,Arial,24,&H00FFFFFF,&H000000FF,&H00000000,&H64000000,"
            "-1,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1\n"
            "[Events]\n"
            "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"
        )
        with open(outfile, "w", encoding="utf-8") as f:
            f.write(header)
            for s in segs:
                f.write(
                    f"Dialogue: 0,{self._ts_ass(s['start'])},{self._ts_ass(s['end'])},"
                    f"Default,{s['speaker']},0,0,0,,{s['text']}\n"
                )

    # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ run —É–¥–∞–ª–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –≤—ã—à–µ
