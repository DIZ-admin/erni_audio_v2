# pipeline/checkpoint_manager.py

import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum


def load_json(file_path):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_json(data, file_path):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


class PipelineStage(Enum):
    """–≠—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    AUDIO_CONVERSION = "audio_conversion"
    DIARIZATION = "diarization"
    TRANSCRIPTION = "transcription"
    MERGE = "merge"
    EXPORT = "export"
    IDENTIFICATION = "identification"
    REPLICATE = "replicate"


@dataclass
class CheckpointData:
    """–î–∞–Ω–Ω—ã–µ checkpoint'–∞"""
    stage: str
    timestamp: str
    input_file: str
    output_file: str
    metadata: Dict[str, Any]
    success: bool
    error_message: Optional[str] = None


@dataclass
class PipelineState:
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    input_file: str
    pipeline_id: str
    created_at: str
    last_updated: str
    completed_stages: List[str]
    current_stage: Optional[str]
    failed_stage: Optional[str]
    checkpoints: List[CheckpointData]
    metadata: Dict[str, Any]


class CheckpointManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä checkpoint'–æ–≤ –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.
    
    –§—É–Ω–∫—Ü–∏–∏:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
    - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - –û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö checkpoint'–æ–≤
    """
    
    def __init__(self, checkpoints_dir: Path = Path("data/checkpoints")):
        self.checkpoints_dir = checkpoints_dir
        self.checkpoints_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logging.getLogger(__name__)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —ç—Ç–∞–ø–æ–≤
        self.stage_order = [
            PipelineStage.AUDIO_CONVERSION,
            PipelineStage.DIARIZATION,
            PipelineStage.TRANSCRIPTION,
            PipelineStage.MERGE,
            PipelineStage.EXPORT
        ]
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–∞–π–ø–ª–∞–π–Ω—ã
        self.replicate_order = [
            PipelineStage.REPLICATE,
            PipelineStage.EXPORT
        ]
        
        self.identification_order = [
            PipelineStage.IDENTIFICATION,
            PipelineStage.EXPORT
        ]
    
    def get_pipeline_id(self, input_file: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        input_path = Path(input_file)
        return f"{input_path.stem}_{hash(input_path.absolute())}"
    
    def get_state_file(self, pipeline_id: str) -> Path:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        return self.checkpoints_dir / f"{pipeline_id}_state.json"
    
    def load_pipeline_state(self, input_file: str) -> Optional[PipelineState]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –µ—Å–ª–∏ –æ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        pipeline_id = self.get_pipeline_id(input_file)
        state_file = self.get_state_file(pipeline_id)
        
        if not state_file.exists():
            return None
        
        try:
            data = load_json(state_file)
            checkpoints = [CheckpointData(**cp) for cp in data.get('checkpoints', [])]
            
            state = PipelineState(
                input_file=data['input_file'],
                pipeline_id=data['pipeline_id'],
                created_at=data['created_at'],
                last_updated=data['last_updated'],
                completed_stages=data['completed_stages'],
                current_stage=data.get('current_stage'),
                failed_stage=data.get('failed_stage'),
                checkpoints=checkpoints,
                metadata=data.get('metadata', {})
            )
            
            self.logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞: {pipeline_id}")
            return state
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è {pipeline_id}: {e}")
            return None
    
    def save_pipeline_state(self, state: PipelineState) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        try:
            state_file = self.get_state_file(state.pipeline_id)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            state.last_updated = datetime.now().isoformat()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            data = asdict(state)
            
            save_json(data, state_file)
            self.logger.debug(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {state_file}")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
    
    def create_checkpoint(self, input_file: str, stage: PipelineStage, 
                         output_file: str, metadata: Dict[str, Any] = None,
                         success: bool = True, error_message: str = None) -> None:
        """–°–æ–∑–¥–∞–µ—Ç checkpoint –¥–ª—è —ç—Ç–∞–ø–∞"""
        pipeline_id = self.get_pipeline_id(input_file)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        state = self.load_pipeline_state(input_file)
        if state is None:
            state = PipelineState(
                input_file=input_file,
                pipeline_id=pipeline_id,
                created_at=datetime.now().isoformat(),
                last_updated=datetime.now().isoformat(),
                completed_stages=[],
                current_stage=stage.value,
                failed_stage=None,
                checkpoints=[],
                metadata=metadata or {}
            )
        
        # –°–æ–∑–¥–∞–µ–º checkpoint
        checkpoint = CheckpointData(
            stage=stage.value,
            timestamp=datetime.now().isoformat(),
            input_file=input_file,
            output_file=output_file,
            metadata=metadata or {},
            success=success,
            error_message=error_message
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        state.checkpoints.append(checkpoint)
        
        if success:
            if stage.value not in state.completed_stages:
                state.completed_stages.append(stage.value)
            state.failed_stage = None
            self.logger.info(f"‚úÖ Checkpoint —Å–æ–∑–¥–∞–Ω: {stage.value} ‚Üí {output_file}")
        else:
            state.failed_stage = stage.value
            self.logger.error(f"‚ùå Checkpoint —Å –æ—à–∏–±–∫–æ–π: {stage.value} - {error_message}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.save_pipeline_state(state)
    
    def get_resume_point(self, input_file: str, pipeline_type: str = "standard") -> Tuple[Optional[PipelineStage], List[str]]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ—á–∫—É –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.
        
        Returns:
            Tuple[next_stage, existing_files] - —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø –∏ —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
        """
        state = self.load_pipeline_state(input_file)
        
        if state is None:
            return None, []
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ —ç—Ç–∞–ø–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
        if pipeline_type == "replicate":
            stage_order = self.replicate_order
        elif pipeline_type == "identification":
            stage_order = self.identification_order
        else:
            stage_order = self.stage_order
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π —ç—Ç–∞–ø
        completed_stages = set(state.completed_stages)
        existing_files = []
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
        for checkpoint in state.checkpoints:
            if checkpoint.success and Path(checkpoint.output_file).exists():
                existing_files.append(checkpoint.output_file)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π —ç—Ç–∞–ø
        for i, stage in enumerate(stage_order):
            if stage.value not in completed_stages:
                self.logger.info(f"üîÑ –¢–æ—á–∫–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {stage.value}")
                return stage, existing_files
        
        # –í—Å–µ —ç—Ç–∞–ø—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã
        self.logger.info("‚úÖ –ü–∞–π–ø–ª–∞–π–Ω —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
        return None, existing_files
    
    def validate_checkpoint_files(self, input_file: str) -> Dict[str, bool]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å checkpoint —Ñ–∞–π–ª–æ–≤"""
        state = self.load_pipeline_state(input_file)
        
        if state is None:
            return {}
        
        validation_results = {}
        
        for checkpoint in state.checkpoints:
            if not checkpoint.success:
                continue
                
            file_path = Path(checkpoint.output_file)
            is_valid = False
            
            if file_path.exists():
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                    if file_path.stat().st_size > 0:
                        # –î–ª—è JSON —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                        if file_path.suffix == '.json':
                            load_json(file_path)
                        is_valid = True
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ñ–∞–π–ª {file_path}: {e}")
            
            validation_results[checkpoint.output_file] = is_valid
        
        return validation_results
    
    def cleanup_old_checkpoints(self, days_old: int = 7) -> int:
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ checkpoint'—ã"""
        from datetime import timedelta
        
        cutoff_date = datetime.now() - timedelta(days=days_old)
        removed_count = 0
        
        for state_file in self.checkpoints_dir.glob("*_state.json"):
            try:
                data = load_json(state_file)
                created_at = datetime.fromisoformat(data.get('created_at', ''))
                
                if created_at < cutoff_date:
                    state_file.unlink()
                    removed_count += 1
                    self.logger.debug(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π checkpoint: {state_file}")
                    
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {state_file}: {e}")
        
        if removed_count > 0:
            self.logger.info(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} —Å—Ç–∞—Ä—ã—Ö checkpoint'–æ–≤")
        
        return removed_count
    
    def get_pipeline_summary(self, input_file: str) -> Optional[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        state = self.load_pipeline_state(input_file)
        
        if state is None:
            return None
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_checkpoints = len(state.checkpoints)
        successful_checkpoints = sum(1 for cp in state.checkpoints if cp.success)
        failed_checkpoints = total_checkpoints - successful_checkpoints
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        if state.failed_stage:
            status = "failed"
        elif len(state.completed_stages) == 0:
            status = "not_started"
        elif state.current_stage:
            status = "in_progress"
        else:
            status = "completed"
        
        return {
            "pipeline_id": state.pipeline_id,
            "input_file": state.input_file,
            "status": status,
            "created_at": state.created_at,
            "last_updated": state.last_updated,
            "completed_stages": state.completed_stages,
            "current_stage": state.current_stage,
            "failed_stage": state.failed_stage,
            "total_checkpoints": total_checkpoints,
            "successful_checkpoints": successful_checkpoints,
            "failed_checkpoints": failed_checkpoints,
            "metadata": state.metadata
        }
