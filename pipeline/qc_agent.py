# pipeline/qc_agent.py

import json
import logging
import statistics
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from pydub import AudioSegment
from dataclasses import dataclass

TARGET_SR = 16_000

@dataclass
class QualityMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    total_segments: int
    total_duration: float
    speakers_count: int
    average_segment_duration: float
    min_segment_duration: float
    max_segment_duration: float
    speaker_distribution: Dict[str, float]
    silence_ratio: float
    quality_score: float
    issues: List[str]

@dataclass
class ValidationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    is_valid: bool
    quality_metrics: QualityMetrics
    recommendations: List[str]
    warnings: List[str]
    errors: List[str]

class QCAgent:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.

    –§—É–Ω–∫—Ü–∏–∏:
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
    - –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    - –°–æ–∑–¥–∞–Ω–∏–µ voiceprint'–æ–≤
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –æ –∫–∞—á–µ—Å—Ç–≤–µ
    """

    def __init__(self, manifest_dir: Optional[Path] = None, per_speaker_sec: int = 30,
                 min_segment_duration: float = 0.5, max_silence_gap: float = 5.0):
        """
        Args:
            manifest_dir: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è WAV-—ç—Ç–∞–ª–æ–Ω–æ–≤ voiceprints
            per_speaker_sec: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—É–Ω–¥ —Ä–µ—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
            min_segment_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ (—Å–µ–∫)
            max_silence_gap: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ (—Å–µ–∫)
        """
        self.manifest_dir = manifest_dir
        self.per_speaker_sec = per_speaker_sec
        self.min_segment_duration = min_segment_duration
        self.max_silence_gap = max_silence_gap
        self.logger = logging.getLogger(__name__)

    def validate_timestamps(self, segments: List[Dict[str, Any]]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö

        Args:
            segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        """
        issues = []

        if not segments:
            issues.append("–ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return issues

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç
        for i, segment in enumerate(segments):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            if 'start' not in segment or 'end' not in segment:
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏")
                continue

            start = segment['start']
            end = segment['end']

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
            if start < 0:
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ ({start})")

            if end <= start:
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è <= –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞ ({start}-{end})")

            if end - start < self.min_segment_duration:
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({end - start:.2f}—Å)")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Å–µ–≥–º–µ–Ω—Ç–æ–º
            if i > 0:
                prev_end = segments[i-1]['end']
                if start < prev_end:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç—ã {i-1} –∏ {i}: –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫")
                elif start - prev_end > self.max_silence_gap:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç—ã {i-1} –∏ {i}: –±–æ–ª—å—à–æ–π —Ä–∞–∑—Ä—ã–≤ ({start - prev_end:.2f}—Å)")

        return issues

    def analyze_diarization_quality(self, diar_segments: List[Dict[str, Any]]) -> QualityMetrics:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏

        Args:
            diar_segments: –°–µ–≥–º–µ–Ω—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏

        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        """
        if not diar_segments:
            return QualityMetrics(
                total_segments=0, total_duration=0.0, speakers_count=0,
                average_segment_duration=0.0, min_segment_duration=0.0, max_segment_duration=0.0,
                speaker_distribution={}, silence_ratio=1.0, quality_score=0.0,
                issues=["–ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏"]
            )

        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        total_segments = len(diar_segments)
        durations = [seg['end'] - seg['start'] for seg in diar_segments]
        total_duration = sum(durations)

        # –ê–Ω–∞–ª–∏–∑ —Å–ø–∏–∫–µ—Ä–æ–≤
        speakers = set(seg.get('speaker', 'UNKNOWN') for seg in diar_segments)
        speakers_count = len(speakers)

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        speaker_time = {}
        for seg in diar_segments:
            speaker = seg.get('speaker', 'UNKNOWN')
            duration = seg['end'] - seg['start']
            speaker_time[speaker] = speaker_time.get(speaker, 0) + duration

        speaker_distribution = {
            speaker: time / total_duration if total_duration > 0 else 0
            for speaker, time in speaker_time.items()
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        average_segment_duration = statistics.mean(durations) if durations else 0
        min_segment_duration = min(durations) if durations else 0
        max_segment_duration = max(durations) if durations else 0

        # –ê–Ω–∞–ª–∏–∑ –ø–∞—É–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        total_audio_time = max(seg['end'] for seg in diar_segments) if diar_segments else 0
        silence_ratio = max(0, (total_audio_time - total_duration) / total_audio_time) if total_audio_time > 0 else 0

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-1)
        quality_score = self._calculate_quality_score(
            speakers_count, average_segment_duration, silence_ratio, speaker_distribution
        )

        # –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
        issues = self.validate_timestamps(diar_segments)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if speakers_count < 2:
            issues.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä")
        elif speakers_count > 10:
            issues.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–æ–≤ ({speakers_count})")

        if average_segment_duration < 1.0:
            issues.append("–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Å—Ä–µ–¥–Ω–µ–º")

        if silence_ratio > 0.5:
            issues.append("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–∞—É–∑ –≤ –∑–∞–ø–∏—Å–∏")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å —Å–ø–∏–∫–µ—Ä–æ–≤
        if speaker_distribution:
            max_speaker_ratio = max(speaker_distribution.values())
            if max_speaker_ratio > 0.8:
                issues.append("–û–¥–∏–Ω —Å–ø–∏–∫–µ—Ä –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç –≤ –∑–∞–ø–∏—Å–∏")

        return QualityMetrics(
            total_segments=total_segments,
            total_duration=total_duration,
            speakers_count=speakers_count,
            average_segment_duration=average_segment_duration,
            min_segment_duration=min_segment_duration,
            max_segment_duration=max_segment_duration,
            speaker_distribution=speaker_distribution,
            silence_ratio=silence_ratio,
            quality_score=quality_score,
            issues=issues
        )

    def _calculate_quality_score(self, speakers_count: int, avg_duration: float,
                               silence_ratio: float, speaker_distribution: Dict[str, float]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ (0-1)"""
        score = 1.0

        # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤
        if speakers_count < 2:
            score *= 0.5
        elif speakers_count > 6:
            score *= 0.8

        # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        if avg_duration < 1.0:
            score *= 0.7
        elif avg_duration < 2.0:
            score *= 0.9

        # –®—Ç—Ä–∞—Ñ –∑–∞ –º–Ω–æ–≥–æ –ø–∞—É–∑
        if silence_ratio > 0.3:
            score *= (1.0 - silence_ratio)

        # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–ø–∏–∫–µ—Ä–æ–≤
        if speaker_distribution:
            max_ratio = max(speaker_distribution.values())
            if max_ratio > 0.7:
                score *= (1.0 - (max_ratio - 0.7) * 2)

        return max(0.0, min(1.0, score))

    def validate_transcription_quality(self, merged_segments: List[Dict[str, Any]]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

        Args:
            merged_segments: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        """
        issues = []

        if not merged_segments:
            issues.append("–ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
            return issues

        total_text_length = 0
        empty_segments = 0

        for i, segment in enumerate(merged_segments):
            text = segment.get('text', '').strip()

            if not text:
                empty_segments += 1
                issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –ø—É—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è")
            else:
                total_text_length += len(text)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
                duration = segment.get('end', 0) - segment.get('start', 0)
                if duration > 5.0 and len(text) < 10:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ {duration:.1f}—Å")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è —Ç–µ–∫—Å—Ç
                if text.lower() in ['[music]', '[silence]', '[noise]', '...']:
                    issues.append(f"–°–µ–≥–º–µ–Ω—Ç {i}: –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è —Ä–µ—á—å ({text})")

        # –û–±—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if empty_segments > len(merged_segments) * 0.3:
            issues.append(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—É—Å—Ç—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ({empty_segments}/{len(merged_segments)})")

        if total_text_length < 100:
            issues.append("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")

        return issues

    def generate_quality_report(self, validation_result: ValidationResult,
                              output_path: Optional[Path] = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ

        Args:
            validation_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞

        Returns:
            –¢–µ–∫—Å—Ç –æ—Ç—á–µ—Ç–∞
        """
        metrics = validation_result.quality_metrics

        report = []
        report.append("# –û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ\n")

        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        report.append(f"## –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {metrics.quality_score:.2f}/1.00\n")

        if validation_result.is_valid:
            report.append("‚úÖ **–°—Ç–∞—Ç—É—Å:** –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞\n")
        else:
            report.append("‚ùå **–°—Ç–∞—Ç—É—Å:** –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã\n")

        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        report.append("## –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n")
        report.append(f"- **–í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:** {metrics.total_segments}")
        report.append(f"- **–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {metrics.total_duration:.2f} —Å–µ–∫—É–Ω–¥")
        report.append(f"- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤:** {metrics.speakers_count}")
        report.append(f"- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞:** {metrics.average_segment_duration:.2f} —Å–µ–∫—É–Ω–¥")
        report.append(f"- **–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–∞—É–∑:** {metrics.silence_ratio:.2%}\n")

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        if metrics.speaker_distribution:
            report.append("## –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º\n")
            for speaker, ratio in sorted(metrics.speaker_distribution.items()):
                report.append(f"- **{speaker}:** {ratio:.1%} ({ratio * metrics.total_duration:.1f}—Å)")
            report.append("")

        # –ü—Ä–æ–±–ª–µ–º—ã –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if validation_result.errors:
            report.append("## ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n")
            for error in validation_result.errors:
                report.append(f"- {error}")
            report.append("")

        if validation_result.warnings:
            report.append("## ‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è\n")
            for warning in validation_result.warnings:
                report.append(f"- {warning}")
            report.append("")

        if metrics.issues:
            report.append("## üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã\n")
            for issue in metrics.issues:
                report.append(f"- {issue}")
            report.append("")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if validation_result.recommendations:
            report.append("## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n")
            for rec in validation_result.recommendations:
                report.append(f"- {rec}")
            report.append("")

        report_text = "\n".join(report)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
        if output_path:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text(report_text, encoding='utf-8')
            self.logger.info(f"üìÑ –û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")

        return report_text

    def validate_pipeline_results(self, wav_local: Path, diar_segments: List[Dict[str, Any]],
                                merged_segments: Optional[List[Dict[str, Any]]] = None) -> ValidationResult:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ pipeline

        Args:
            wav_local: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
            diar_segments: –°–µ–≥–º–µ–Ω—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
            merged_segments: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        quality_metrics = self.analyze_diarization_quality(diar_segments)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã
        all_issues = quality_metrics.issues.copy()
        warnings = []
        errors = []
        recommendations = []

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        if merged_segments:
            transcription_issues = self.validate_transcription_quality(merged_segments)
            all_issues.extend(transcription_issues)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã
        for issue in all_issues:
            if any(keyword in issue.lower() for keyword in ['–æ—à–∏–±–∫–∞', '–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç', '–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ']):
                errors.append(issue)
            else:
                warnings.append(issue)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if quality_metrics.speakers_count < 2:
            recommendations.append("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ - –≤–æ–∑–º–æ–∂–Ω–æ –Ω—É–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")

        if quality_metrics.average_segment_duration < 1.0:
            recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        if quality_metrics.silence_ratio > 0.4:
            recommendations.append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—Ä–µ–∑–∫–∏ –ø–∞—É–∑ –≤ –∞—É–¥–∏–æ")

        if quality_metrics.speakers_count > 6:
            recommendations.append("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ - –≤–æ–∑–º–æ–∂–Ω–æ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        is_valid = len(errors) == 0 and quality_metrics.quality_score >= 0.5

        return ValidationResult(
            is_valid=is_valid,
            quality_metrics=quality_metrics,
            recommendations=recommendations,
            warnings=warnings,
            errors=errors
        )

    def extract_voiceprints(self, wav_path: Path, diar: List[Dict[str, Any]]):
        """
        –°–æ–∑–¥–∞—ë—Ç WAV-—ç—Ç–∞–ª–æ–Ω—ã ‚â§ per_speaker_sec –¥–ª—è –∫–∞–∂–¥–æ–≥–æ speaker –≤ diar.
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∫–∞—á–µ—Å—Ç–≤–∞.
        """
        if not self.manifest_dir:
            return

        self.manifest_dir.mkdir(parents=True, exist_ok=True)

        try:
            audio = AudioSegment.from_wav(wav_path)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ {wav_path}: {e}")
            return

        manifest = {}
        grouped = {}

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
        for seg in diar:
            speaker = seg.get("speaker", "UNKNOWN")
            grouped.setdefault(speaker, []).append(seg)

        self.logger.info(f"üé§ –°–æ–∑–¥–∞—é voiceprints –¥–ª—è {len(grouped)} —Å–ø–∏–∫–µ—Ä–æ–≤...")

        for spk, segs in grouped.items():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
            segs_sorted = sorted(segs, key=lambda x: x["end"] - x["start"], reverse=True)

            collected = AudioSegment.empty()
            segments_used = 0

            for seg in segs_sorted:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                duration = seg["end"] - seg["start"]
                if duration < 0.5:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Å–µ–≥–º–µ–Ω—Ç
                    continue

                try:
                    snippet = audio[int(1000 * seg["start"]) : int(1000 * seg["end"])]
                    collected += snippet
                    segments_used += 1

                    if len(collected) >= self.per_speaker_sec * 1000:
                        break
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {seg}: {e}")
                    continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if len(collected) < 5_000:  # –ú–∏–Ω–∏–º—É–º 5 —Å–µ–∫—É–Ω–¥
                self.logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {spk}: {len(collected)/1000:.1f}—Å")
                continue

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º voiceprint
            out_file = self.manifest_dir / f"{spk}.wav"
            try:
                collected.set_frame_rate(TARGET_SR).set_channels(1).export(out_file, format="wav")
                manifest[spk] = {
                    "file": out_file.as_posix(),
                    "duration": len(collected) / 1000,
                    "segments_used": segments_used,
                    "quality": "good" if len(collected) >= 10_000 else "acceptable"
                }
                self.logger.info(f"üíæ Voiceprint —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {spk} ‚Üí {out_file} ({len(collected)/1000:.1f}—Å)")
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è voiceprint –¥–ª—è {spk}: {e}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç
        if manifest:
            manifest_path = self.manifest_dir / "manifest.json"
            try:
                manifest_path.write_text(json.dumps(manifest, indent=2, ensure_ascii=False))
                self.logger.info(f"üìÑ –ú–∞–Ω–∏—Ñ–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {manifest_path}")
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞: {e}")
        else:
            self.logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ voiceprint")

    def run(self, wav_local: Path, diar: List[Dict[str, Any]],
            merged_segments: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ QC –∞–≥–µ–Ω—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é

        Args:
            wav_local: –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É WAV —Ñ–∞–π–ª—É
            diar: –°–µ–≥–º–µ–Ω—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
            merged_segments: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ —Å–æ–∑–¥–∞–≤–∞–ª–∏—Å—å voiceprints
        """
        self.logger.info(f"üîç QC Agent: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é
        validation_result = self.validate_pipeline_results(wav_local, diar, merged_segments)

        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        if validation_result.is_valid:
            self.logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ (–∫–∞—á–µ—Å—Ç–≤–æ: {validation_result.quality_metrics.quality_score:.2f})")
        else:
            self.logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–æ—Ü–µ–Ω–∫–∞: {validation_result.quality_metrics.quality_score:.2f})")
            for error in validation_result.errors:
                self.logger.error(f"‚ùå {error}")
            for warning in validation_result.warnings:
                self.logger.warning(f"‚ö†Ô∏è {warning}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ
        if wav_local.parent.name == "interim" or "interim" in str(wav_local):
            report_dir = Path("data/interim")
        else:
            report_dir = wav_local.parent

        report_path = report_dir / f"{wav_local.stem}_quality_report.md"
        self.generate_quality_report(validation_result, report_path)

        # –°–æ–∑–¥–∞–µ–º voiceprints –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if self.manifest_dir:
            self.logger.info("üé§ –°–æ–∑–¥–∞—é voiceprints...")
            self.extract_voiceprints(wav_local, diar)
            return []  # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è pipeline
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            return merged_segments if merged_segments else diar

    def extract_voiceprints(self, wav_path: Path, diar: List[Dict[str, Any]]):
        """
        –°–æ–∑–¥–∞—ë—Ç WAV-—ç—Ç–∞–ª–æ–Ω—ã ‚â§ per_speaker_sec –¥–ª—è –∫–∞–∂–¥–æ–≥–æ speaker –≤ diar.
        –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É extract_voiceprints, —Ç–æ–ª—å–∫–æ –Ω–∞–∑—ã–≤–∞–µ–º Skeleton "Agent".
        """
        if not self.manifest_dir:
            return

        self.manifest_dir.mkdir(parents=True, exist_ok=True)
        audio = AudioSegment.from_wav(wav_path)
        manifest = {}
        grouped = {}
        for seg in diar:
            grouped.setdefault(seg["speaker"], []).append(seg)

        for spk, segs in grouped.items():
            collected = AudioSegment.empty()
            for seg in segs:
                snippet = audio[int(1000 * seg["start"]) : int(1000 * seg["end"])]
                collected += snippet
                if len(collected) >= self.per_speaker_sec * 1000:
                    break
            if len(collected) < 5_000:
                continue

            out_file = self.manifest_dir / f"{spk}.wav"
            collected.set_frame_rate(TARGET_SR).set_channels(1).export(out_file, format="wav")
            manifest[spk] = out_file.as_posix()
            print(f"üíæ  QCAgent: saved voiceprint ‚Üí {out_file}")

        manifest_path = self.manifest_dir / "manifest.json"
        manifest_path.write_text(json.dumps(manifest, indent=2, ensure_ascii=False))
        print(f"üìÑ  QCAgent: manifest written ‚Üí {manifest_path}")

    def run(self, wav_local: Path, diar: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ï—Å–ª–∏ manifest_dir –∑–∞–¥–∞–Ω, —Ä–µ–∂–µ–º WAV –Ω–∞ —ç—Ç–∞–ª–æ–Ω—ã –∏ –≤—ã—Ö–æ–¥–∏–º (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º [], –ø–æ—Ç–æ–º—É —á—Ç–æ
        –¥–∞–ª—å–Ω–µ–π—à–∏–µ –∞–≥–µ–Ω—Ç—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è). –ï—Å–ª–∏ manifest_dir = None, –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞—ë–º diar –¥–∞–ª—å—à–µ.
        """
        if self.manifest_dir:
            self.extract_voiceprints(wav_local, diar)
            return []  # —Å–∏–≥–Ω–∞–ª, —á—Ç–æ pipeline –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è
        else:
            return diar  # –ø–µ—Ä–µ–¥–∞—ë–º ¬´–≤–ø–µ—Ä–µ–¥¬ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
