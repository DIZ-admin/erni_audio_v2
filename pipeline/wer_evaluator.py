"""
WER Evaluator - –ú–æ–¥—É–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
–í—ã—á–∏—Å–ª—è–µ—Ç WER (Word Error Rate) –∏ CER (Character Error Rate) –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
"""

import logging
import time
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import re
from dataclasses import dataclass
from datetime import datetime


@dataclass
class TranscriptionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏"""
    model_name: str
    segments: List[Dict]
    processing_time: float
    estimated_cost: str
    success: bool
    error: Optional[str] = None
    
    @property
    def full_text(self) -> str:
        """–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        if not self.segments:
            return ""
        return " ".join(seg.get("text", "") for seg in self.segments).strip()


@dataclass
class QualityMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    wer: float  # Word Error Rate (0.0 - 1.0)
    cer: float  # Character Error Rate (0.0 - 1.0)
    word_accuracy: float  # 1 - WER
    char_accuracy: float  # 1 - CER
    reference_words: int
    hypothesis_words: int
    reference_chars: int
    hypothesis_chars: int
    
    def to_dict(self) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        return {
            "wer": round(self.wer, 4),
            "cer": round(self.cer, 4),
            "word_accuracy": round(self.word_accuracy, 4),
            "char_accuracy": round(self.char_accuracy, 4),
            "reference_words": self.reference_words,
            "hypothesis_words": self.hypothesis_words,
            "reference_chars": self.reference_chars,
            "hypothesis_chars": self.hypothesis_chars
        }


class WERCalculator:
    """–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è WER –∏ CER"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def normalize_text(self, text: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()
        
        # –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'[^\w\s]', '', text)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def calculate_edit_distance(self, ref_tokens: List[str], hyp_tokens: List[str]) -> Tuple[int, List[List[int]]]:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞) –º–µ–∂–¥—É –¥–≤—É–º—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ —Ç–æ–∫–µ–Ω–æ–≤
        
        Args:
            ref_tokens: –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
            hyp_tokens: –ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ç–æ–∫–µ–Ω—ã
            
        Returns:
            Tuple[—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ_—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –º–∞—Ç—Ä–∏—Ü–∞_dp]
        """
        m, n = len(ref_tokens), len(hyp_tokens)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if ref_tokens[i-1] == hyp_tokens[j-1]:
                    dp[i][j] = dp[i-1][j-1]  # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                else:
                    dp[i][j] = 1 + min(
                        dp[i-1][j],    # –£–¥–∞–ª–µ–Ω–∏–µ
                        dp[i][j-1],    # –í—Å—Ç–∞–≤–∫–∞
                        dp[i-1][j-1]   # –ó–∞–º–µ–Ω–∞
                    )
        
        return dp[m][n], dp
    
    def calculate_wer(self, reference: str, hypothesis: str) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç WER (Word Error Rate)
        
        Args:
            reference: –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            hypothesis: –ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            
        Returns:
            WER –∑–Ω–∞—á–µ–Ω–∏–µ (0.0 - 1.0)
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã
        ref_normalized = self.normalize_text(reference)
        hyp_normalized = self.normalize_text(hypothesis)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        ref_words = ref_normalized.split()
        hyp_words = hyp_normalized.split()
        
        if not ref_words:
            return 1.0 if hyp_words else 0.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        edit_distance, _ = self.calculate_edit_distance(ref_words, hyp_words)
        
        # WER = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ / –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —ç—Ç–∞–ª–æ–Ω–µ
        wer = edit_distance / len(ref_words)
        
        return min(wer, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º 1.0
    
    def calculate_cer(self, reference: str, hypothesis: str) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç CER (Character Error Rate)
        
        Args:
            reference: –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            hypothesis: –ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            
        Returns:
            CER –∑–Ω–∞—á–µ–Ω–∏–µ (0.0 - 1.0)
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã
        ref_normalized = self.normalize_text(reference)
        hyp_normalized = self.normalize_text(hypothesis)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–∏–º–≤–æ–ª—ã
        ref_chars = list(ref_normalized.replace(' ', ''))  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –¥–ª—è CER
        hyp_chars = list(hyp_normalized.replace(' ', ''))
        
        if not ref_chars:
            return 1.0 if hyp_chars else 0.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        edit_distance, _ = self.calculate_edit_distance(ref_chars, hyp_chars)
        
        # CER = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ / –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —ç—Ç–∞–ª–æ–Ω–µ
        cer = edit_distance / len(ref_chars)
        
        return min(cer, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º 1.0
    
    def calculate_metrics(self, reference: str, hypothesis: str) -> QualityMetrics:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        
        Args:
            reference: –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            hypothesis: –ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            
        Returns:
            QualityMetrics –æ–±—ä–µ–∫—Ç —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã
        ref_normalized = self.normalize_text(reference)
        hyp_normalized = self.normalize_text(hypothesis)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ –∏ —Å–∏–º–≤–æ–ª—ã
        ref_words = ref_normalized.split()
        hyp_words = hyp_normalized.split()
        ref_chars = list(ref_normalized.replace(' ', ''))
        hyp_chars = list(hyp_normalized.replace(' ', ''))
        
        # –í—ã—á–∏—Å–ª—è–µ–º WER –∏ CER
        wer = self.calculate_wer(reference, hypothesis)
        cer = self.calculate_cer(reference, hypothesis)
        
        return QualityMetrics(
            wer=wer,
            cer=cer,
            word_accuracy=1.0 - wer,
            char_accuracy=1.0 - cer,
            reference_words=len(ref_words),
            hypothesis_words=len(hyp_words),
            reference_chars=len(ref_chars),
            hypothesis_chars=len(hyp_chars)
        )


class WERTranscriptionEvaluator:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.calculator = WERCalculator()
        self.results = {}
        
    def evaluate_transcription(self, 
                             reference_text: str, 
                             transcription_result: TranscriptionResult) -> Dict:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        
        Args:
            reference_text: –≠—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            transcription_result: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü–µ–Ω–∫–∏
        """
        if not transcription_result.success:
            return {
                "model": transcription_result.model_name,
                "success": False,
                "error": transcription_result.error,
                "processing_time": transcription_result.processing_time,
                "estimated_cost": transcription_result.estimated_cost
            }
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        metrics = self.calculator.calculate_metrics(reference_text, transcription_result.full_text)
        
        result = {
            "model": transcription_result.model_name,
            "success": True,
            "processing_time": transcription_result.processing_time,
            "estimated_cost": transcription_result.estimated_cost,
            "segments_count": len(transcription_result.segments),
            "quality_metrics": metrics.to_dict(),
            "transcribed_text": transcription_result.full_text[:200] + "..." if len(transcription_result.full_text) > 200 else transcription_result.full_text
        }
        
        self.logger.info(f"üìä {transcription_result.model_name}: WER={metrics.wer:.3f}, CER={metrics.cer:.3f}, –≤—Ä–µ–º—è={transcription_result.processing_time:.2f}—Å")
        
        return result
    
    def save_results(self, results: Dict, output_path: Path) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –≤ JSON —Ñ–∞–π–ª
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        results_with_metadata = {
            "evaluation_metadata": {
                "timestamp": datetime.now().isoformat(),
                "evaluator_version": "1.0.0",
                "total_models_tested": len([r for r in results.get("model_results", {}).values() if r.get("success", False)])
            },
            **results
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_with_metadata, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
