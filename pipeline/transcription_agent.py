# pipeline/transcription_agent.py

import logging
from openai import OpenAI
from pathlib import Path
from typing import List, Dict, Optional, Any
import openai
import time
import subprocess
import tempfile
import uuid
import random
import asyncio
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor, as_completed
from pydub import AudioSegment
from .config import ConfigurationManager
from .base_agent import BaseAgent
from .validation_mixin import ValidationMixin
from .retry_mixin import RetryMixin
from .rate_limit_mixin import RateLimitMixin
from .constants import (
    SUPPORTED_TRANSCRIPTION_MODELS,
    DEFAULT_MAX_CONCURRENT_CHUNKS,
    DEFAULT_CHUNK_TIMEOUT_MINUTES
)

class TranscriptionAgent(BaseAgent, ValidationMixin, RetryMixin, RateLimitMixin):
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenAI Speech-to-Text –º–æ–¥–µ–ª—è–º–∏.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏:
    id, start, end, text, tokens, avg_logprob, no_speech_prob, temperature, compression_ratio.
    """

    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–∏–∑ –∫–æ–Ω—Å—Ç–∞–Ω—Ç)
    SUPPORTED_MODELS = SUPPORTED_TRANSCRIPTION_MODELS

    def __init__(self, api_key: str, model: str = "whisper-1", language: Optional[str] = None, response_format: str = "auto"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.

        Args:
            api_key: OpenAI API –∫–ª—é—á
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (whisper-1, gpt-4o-mini-transcribe, gpt-4o-transcribe)
            language: –ö–æ–¥ —è–∑—ã–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'en', 'ru', 'de') –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            response_format: –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (auto, json, verbose_json, text, srt, vtt)
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        BaseAgent.__init__(self, name="TranscriptionAgent")
        ValidationMixin.__init__(self)
        RetryMixin.__init__(self)
        RateLimitMixin.__init__(self, api_name="openai")

        self.client = OpenAI(api_key=api_key)
        self.model = self._validate_model(model)
        self.language = self.validate_language_code(language)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º ValidationMixin
        self.response_format = self._determine_response_format(response_format)

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.max_concurrent_chunks = DEFAULT_MAX_CONCURRENT_CHUNKS  # –ú–∞–∫—Å–∏–º—É–º 3 —á–∞—Å—Ç–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        self.chunk_timeout = DEFAULT_CHUNK_TIMEOUT_MINUTES * 60  # 30 –º–∏–Ω—É—Ç –Ω–∞ —á–∞—Å—Ç—å

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.parallel_stats = {
            "total_chunks_processed": 0,
            "concurrent_chunks_peak": 0,
            "total_parallel_time": 0.0,
            "chunks_failed": 0,
            "chunks_retried": 0
        }

        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        model_info = self.SUPPORTED_MODELS[self.model]
        self.log_with_emoji("info", "üéØ", f"–ú–æ–¥–µ–ª—å: {model_info['name']} ({model_info['description']})")

    # –£–¥–∞–ª–µ–Ω _get_adaptive_timeout - –∏—Å–ø–æ–ª—å–∑—É–µ–º RetryMixin.get_adaptive_timeout

    # –£–¥–∞–ª–µ–Ω—ã _intelligent_wait_strategy –∏ _log_retry_statistics - –∏—Å–ø–æ–ª—å–∑—É–µ–º RetryMixin

    def _log_parallel_statistics(self):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        if self.parallel_stats["total_chunks_processed"] > 0:
            self.log_with_emoji("info", "üìä",
                f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: "
                f"—á–∞—Å—Ç–µ–π={self.parallel_stats['total_chunks_processed']}, "
                f"–ø–∏–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö={self.parallel_stats['concurrent_chunks_peak']}, "
                f"–≤—Ä–µ–º—è={self.parallel_stats['total_parallel_time']:.1f}—Å, "
                f"–Ω–µ—É–¥–∞—á–Ω—ã—Ö={self.parallel_stats['chunks_failed']}"
            )

    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞
    SUPPORTED_RESPONSE_FORMATS = {
        "auto": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞",
        "json": "–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π JSON —Å –ø–æ–ª–µ–º text",
        "verbose_json": "–ü–æ–¥—Ä–æ–±–Ω—ã–π JSON —Å–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏",
        "text": "–ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ–±—ë—Ä—Ç–∫–∏",
        "srt": "–°—É–±—Ç–∏—Ç—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ SRT",
        "vtt": "–°—É–±—Ç–∏—Ç—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ WebVTT"
    }

    def _validate_model(self, model: str) -> str:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        if model not in self.SUPPORTED_MODELS:
            available_models = ", ".join(self.SUPPORTED_MODELS.keys())
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –º–æ–¥–µ–ª—å '{model}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {available_models}")
        return model

    def _validate_response_format(self, response_format: str) -> str:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞."""
        if response_format not in self.SUPPORTED_RESPONSE_FORMATS:
            available_formats = ", ".join(self.SUPPORTED_RESPONSE_FORMATS.keys())
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç '{response_format}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {available_formats}")
        return response_format

    def _determine_response_format(self, requested_format: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏."""
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        self._validate_response_format(requested_format)

        # –ï—Å–ª–∏ auto, –≤—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if requested_format == "auto":
            if self.SUPPORTED_MODELS[self.model]["supports_verbose_json"]:
                return "verbose_json"  # –î–ª—è whisper-1
            else:
                return "json"  # –î–ª—è gpt-4o –º–æ–¥–µ–ª–µ–π

        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω verbose_json, –Ω–æ –º–æ–¥–µ–ª—å –µ–≥–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
        if requested_format == "verbose_json" and not self.SUPPORTED_MODELS[self.model]["supports_verbose_json"]:
            self.logger.warning(f"–ú–æ–¥–µ–ª—å {self.model} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç verbose_json, –∏—Å–ø–æ–ª—å–∑—É–µ–º json")
            return "json"

        return requested_format

    def run(self, wav_local: Path, prompt: str = "") -> List[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.

        Args:
            wav_local: –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
            prompt: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        start_time = time.time()

        self.start_operation("—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è")

        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ ValidationMixin
            max_size = self.SUPPORTED_MODELS[self.model]["max_file_size_mb"]
            self.validate_audio_file(wav_local, max_size_mb=max_size)

            file_size_mb = wav_local.stat().st_size / (1024 * 1024)  # MB
            model_info = self.SUPPORTED_MODELS[self.model]

            self.log_with_emoji("info", "üéµ", f"–ù–∞—á–∏–Ω–∞—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å {model_info['name']}: {wav_local.name} ({file_size_mb:.1f}MB)")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Ä–∞–∑–±–∏–≤–∞—Ç—å —Ñ–∞–π–ª
            if file_size_mb > max_size:
                result = self._transcribe_large_file(wav_local, prompt)
            else:
                result = self._transcribe_single_file(wav_local, prompt)

            self.end_operation("—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", success=True)
            return result

        except Exception as e:
            self.end_operation("—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", success=False)
            self.handle_error(e, "—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", reraise=True)

    # –£–¥–∞–ª–µ–Ω _validate_audio_file - –∏—Å–ø–æ–ª—å–∑—É–µ–º ValidationMixin.validate_audio_file

    def _split_audio_file(self, wav_local: Path, chunk_duration_minutes: int = 10) -> List[Path]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –±–æ–ª—å—à–æ–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ OpenAI API.

        Args:
            wav_local: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            chunk_duration_minutes: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö

        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —á–∞—Å—Ç—è–º —Ñ–∞–π–ª–∞
        """
        try:
            self.log_with_emoji("info", "‚úÇÔ∏è", f"–†–∞–∑–±–∏–≤–∞—é —Ñ–∞–π–ª {wav_local.name} –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ {chunk_duration_minutes} –º–∏–Ω—É—Ç...")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio = AudioSegment.from_wav(wav_local)
            chunk_duration_ms = chunk_duration_minutes * 60 * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

            chunks = []
            temp_dir = Path(tempfile.gettempdir())

            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
            for i, start_ms in enumerate(range(0, len(audio), chunk_duration_ms)):
                end_ms = min(start_ms + chunk_duration_ms, len(audio))
                chunk = audio[start_ms:end_ms]

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç—å
                chunk_path = temp_dir / f"{wav_local.stem}_chunk_{i:03d}.wav"
                chunk.export(chunk_path, format="wav")
                chunks.append(chunk_path)

                chunk_size_mb = chunk_path.stat().st_size / (1024 * 1024)
                self.log_with_emoji("debug", "üìÑ", f"–°–æ–∑–¥–∞–Ω–∞ —á–∞—Å—Ç—å {i+1}: {chunk_path.name} ({chunk_size_mb:.1f}MB)")

            self.log_with_emoji("info", "‚úÖ", f"–§–∞–π–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞—Å—Ç–µ–π")
            return chunks

        except Exception as e:
            self.handle_error(e, "—Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ñ–∞–π–ª–∞", reraise=True)

    def _transcribe_single_file(self, wav_local: Path, prompt: str = "") -> List[Dict]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π retry –ª–æ–≥–∏–∫–æ–π."""
        file_size_mb = wav_local.stat().st_size / (1024 * 1024)

        # –ü–æ–ª—É—á–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç —á–µ—Ä–µ–∑ RetryMixin
        adaptive_timeout = self.get_adaptive_timeout(file_size_mb)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
        transcription_params = self._prepare_transcription_params(prompt)

        # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è retry
        def transcribe_func():
            return self._transcribe_with_rate_limit(wav_local, transcription_params, adaptive_timeout)

        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å retry –ª–æ–≥–∏–∫–æ–π —á–µ—Ä–µ–∑ RetryMixin
        result = self.retry_with_backoff(
            transcribe_func,
            max_attempts=8,
            base_delay=1.0,
            max_delay=120.0
        )

        self.log_with_emoji("info", "‚úÖ", f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Ñ–∞–π–ª: {file_size_mb:.1f}MB)")
        return result

    def _transcribe_with_rate_limit(self, wav_local: Path, transcription_params: Dict, timeout: float) -> List[Dict]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å rate limiting –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""

        def api_call():
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
            client_with_timeout = self.client.with_options(timeout=timeout)

            with open(wav_local, "rb") as audio_file:
                transcript = client_with_timeout.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    **transcription_params
                )

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            return self._process_transcript_response(transcript)

        # –í—ã–ø–æ–ª–Ω—è–µ–º API –≤—ã–∑–æ–≤ —Å rate limiting
        try:
            return self.with_rate_limit(api_call, operation_key="transcription", timeout=timeout)
        except openai.APIStatusError as e:
            if e.status_code == 429:  # Rate limit
                raise openai.RateLimitError(f"Rate limit: {e}") from e
            else:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ OpenAI API: {e}") from e

    def _process_chunk_parallel(self, chunk_info: Dict) -> Dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É —á–∞—Å—Ç—å —Ñ–∞–π–ª–∞ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ.

        Args:
            chunk_info: –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —á–∞—Å—Ç–∏ —Ñ–∞–π–ª–∞:
                - path: Path –∫ —Ñ–∞–π–ª—É —á–∞—Å—Ç–∏
                - index: –ò–Ω–¥–µ–∫—Å —á–∞—Å—Ç–∏
                - offset: –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                - prompt: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø–æ–¥—Å–∫–∞–∑–∫–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:
                - index: –ò–Ω–¥–µ–∫—Å —á–∞—Å—Ç–∏
                - segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
                - offset: –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ
                - success: –§–ª–∞–≥ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
                - error: –û–ø–∏—Å–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                - processing_time: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        chunk_path = chunk_info["path"]
        chunk_index = chunk_info["index"]
        chunk_offset = chunk_info["offset"]
        prompt = chunk_info["prompt"]

        start_time = time.time()

        try:
            self.log_with_emoji("info", "üîÑ", f"–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —á–∞—Å—Ç–∏ {chunk_index + 1}: {chunk_path.name}")

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —á–∞—Å—Ç—å
            chunk_segments = self._transcribe_single_file(chunk_path, prompt)

            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å —É—á–µ—Ç–æ–º —Å–º–µ—â–µ–Ω–∏—è
            for segment in chunk_segments:
                segment['start'] += chunk_offset
                segment['end'] += chunk_offset
                # ID –±—É–¥–µ—Ç –ø–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤–∞–Ω –ø–æ–∑–∂–µ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏

            processing_time = time.time() - start_time

            self.log_with_emoji("info", "‚úÖ", f"–ß–∞—Å—Ç—å {chunk_index + 1} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {len(chunk_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∑–∞ {processing_time:.2f}—Å")

            return {
                "index": chunk_index,
                "segments": chunk_segments,
                "offset": chunk_offset,
                "success": True,
                "error": None,
                "processing_time": processing_time
            }

        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏ {chunk_index + 1}: {e}"

            self.log_with_emoji("error", "‚ùå", error_msg)
            self.parallel_stats["chunks_failed"] += 1

            return {
                "index": chunk_index,
                "segments": [],
                "offset": chunk_offset,
                "success": False,
                "error": error_msg,
                "processing_time": processing_time
            }

    def _transcribe_large_file(self, wav_local: Path, prompt: str = "") -> List[Dict]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —á–∞—Å—Ç–µ–π."""
        self.log_with_emoji("info", "üöÄ", f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (–º–∞–∫—Å {self.max_concurrent_chunks} –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)...")

        start_time = time.time()

        # –†–∞–∑–±–∏–≤–∞–µ–º —Ñ–∞–π–ª –Ω–∞ —á–∞—Å—Ç–∏
        chunks = self._split_audio_file(wav_local, chunk_duration_minutes=10)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç—è—Ö –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        chunk_infos = []
        for i, chunk_path in enumerate(chunks):
            chunk_info = {
                "path": chunk_path,
                "index": i,
                "offset": i * 10 * 60,  # 10 –º–∏–Ω—É—Ç = 600 —Å–µ–∫—É–Ω–¥
                "prompt": prompt
            }
            chunk_infos.append(chunk_info)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = self._process_chunks_parallel(chunk_infos)

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        all_segments = []
        total_processing_time = 0.0
        successful_chunks = 0

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∏–Ω–¥–µ–∫—Å—É —á–∞—Å—Ç–∏
        results.sort(key=lambda x: x["index"])

        for result in results:
            if result["success"]:
                # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º ID —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                for segment in result["segments"]:
                    segment['id'] = len(all_segments)
                    all_segments.append(segment)

                successful_chunks += 1
                total_processing_time += result["processing_time"]
                self.parallel_stats["total_chunks_processed"] += 1
            else:
                self.log_with_emoji("error", "‚ùå", f"–ß–∞—Å—Ç—å {result['index'] + 1} –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {result['error']}")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        self._cleanup_chunk_files(chunks)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        parallel_duration = time.time() - start_time
        self.parallel_stats["total_parallel_time"] += parallel_duration

        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        speedup_ratio = total_processing_time / parallel_duration if parallel_duration > 0 else 1.0

        self.log_with_emoji("info", "‚úÖ",
            f"–ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(all_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ {successful_chunks}/{len(chunks)} —á–∞—Å—Ç–µ–π"
        )
        self.log_with_emoji("info", "‚ö°",
            f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {parallel_duration:.2f}—Å (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ {speedup_ratio:.1f}x)"
        )

        self._log_parallel_statistics()

        if successful_chunks < len(chunks):
            failed_count = len(chunks) - successful_chunks
            self.log_with_emoji("warning", "‚ö†Ô∏è", f"{failed_count} —á–∞—Å—Ç–µ–π –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å")

        return all_segments

    def _process_chunks_parallel(self, chunk_infos: List[Dict]) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –Ω–∞–≥—Ä—É–∑–∫–∏.

        Args:
            chunk_infos: –°–ø–∏—Å–æ–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —á–∞—Å—Ç—è—Ö —Ñ–∞–π–ª–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        results = []
        active_futures = 0

        self.log_with_emoji("info", "üîÑ", f"–ó–∞–ø—É—Å–∫–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(chunk_infos)} —á–∞—Å—Ç–µ–π (–º–∞–∫—Å {self.max_concurrent_chunks} –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)")

        with ThreadPoolExecutor(max_workers=self.max_concurrent_chunks) as executor:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á–∏ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            future_to_chunk = {}

            for chunk_info in chunk_infos:
                future = executor.submit(self._process_chunk_parallel, chunk_info)
                future_to_chunk[future] = chunk_info
                active_futures += 1

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∏–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
                if active_futures > self.parallel_stats["concurrent_chunks_peak"]:
                    self.parallel_stats["concurrent_chunks_peak"] = active_futures

            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            try:
                for future in as_completed(future_to_chunk, timeout=self.chunk_timeout):
                    chunk_info = future_to_chunk[future]
                    active_futures -= 1

                    try:
                        result = future.result()
                        results.append(result)

                        if result["success"]:
                            self.log_with_emoji("debug", "‚úÖ", f"–ß–∞—Å—Ç—å {result['index'] + 1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                        else:
                            self.log_with_emoji("warning", "‚ùå", f"–ß–∞—Å—Ç—å {result['index'] + 1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–æ–π")

                    except concurrent.futures.TimeoutError:
                        error_msg = f"–¢–∞–π–º–∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏ {chunk_info['index'] + 1}"
                        self.log_with_emoji("error", "‚è∞", error_msg)
                        self.parallel_stats["chunks_failed"] += 1

                        results.append({
                            "index": chunk_info["index"],
                            "segments": [],
                            "offset": chunk_info["offset"],
                            "success": False,
                            "error": error_msg,
                            "processing_time": self.chunk_timeout
                        })

                    except Exception as e:
                        error_msg = f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞—Å—Ç–∏ {chunk_info['index'] + 1}: {e}"
                        self.log_with_emoji("error", "‚ùå", error_msg)
                        self.parallel_stats["chunks_failed"] += 1

                        results.append({
                            "index": chunk_info["index"],
                            "segments": [],
                            "offset": chunk_info["offset"],
                            "success": False,
                            "error": error_msg,
                            "processing_time": 0.0
                        })

            except concurrent.futures.TimeoutError:
                # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç as_completed - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
                self.log_with_emoji("error", "‚è∞", f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ ({self.chunk_timeout}—Å)")

                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
                for future, chunk_info in future_to_chunk.items():
                    if not future.done():
                        error_msg = f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏ {chunk_info['index'] + 1}"
                        self.parallel_stats["chunks_failed"] += 1

                        results.append({
                            "index": chunk_info["index"],
                            "segments": [],
                            "offset": chunk_info["offset"],
                            "success": False,
                            "error": error_msg,
                            "processing_time": self.chunk_timeout
                        })

        self.log_with_emoji("info", "üèÅ", f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results

    def _cleanup_chunk_files(self, chunk_paths: List[Path]) -> None:
        """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —á–∞—Å—Ç–µ–π."""
        for chunk_path in chunk_paths:
            try:
                if chunk_path.exists():
                    chunk_path.unlink()
                    self.log_with_emoji("debug", "üóëÔ∏è", f"–£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {chunk_path.name}")
            except Exception as e:
                self.log_with_emoji("warning", "‚ö†Ô∏è", f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {chunk_path}: {e}")

    def _prepare_transcription_params(self, prompt: str) -> Dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏."""
        params = {
            "response_format": self.response_format,
            "temperature": 0,
        }

        # –î–æ–±–∞–≤–ª—è–µ–º prompt –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
        if prompt and self.SUPPORTED_MODELS[self.model]["supports_prompt"]:
            params["prompt"] = prompt

        # –î–æ–±–∞–≤–ª—è–µ–º —è–∑—ã–∫ –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏ —É–∫–∞–∑–∞–Ω
        if self.language and self.SUPPORTED_MODELS[self.model]["supports_language"]:
            params["language"] = self.language

        return params

    def _process_transcript_response(self, transcript) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞."""

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞
        if self.response_format == "verbose_json":
            # verbose_json –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã
            segments = getattr(transcript, 'segments', [])

            if not segments:
                self.log_with_emoji("warning", "‚ö†Ô∏è", f"–ú–æ–¥–µ–ª—å {self.model} –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ verbose_json")
                return []

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–∏
            processed_segments = []
            for segment in segments:
                if hasattr(segment, 'model_dump'):
                    segment_dict = segment.model_dump()
                elif hasattr(segment, '__dict__'):
                    segment_dict = segment.__dict__
                else:
                    segment_dict = dict(segment)

                processed_segments.append(segment_dict)

            model_info = self.SUPPORTED_MODELS[self.model]
            self.log_with_emoji("info", "üìä", f"{model_info['name']}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (verbose_json)")
            return processed_segments

        elif self.response_format == "json":
            # json –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
            text = getattr(transcript, 'text', '')
            if not text:
                self.log_with_emoji("warning", "‚ö†Ô∏è", f"–ú–æ–¥–µ–ª—å {self.model} –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ç–µ–∫—Å—Ç –≤ json")
                return []

            # –°–æ–∑–¥–∞–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
            duration = getattr(transcript, 'duration', 0.0)
            segment = {
                "id": 0,
                "start": 0.0,
                "end": duration,
                "text": text.strip(),
                "tokens": [],
                "avg_logprob": 0.0,
                "no_speech_prob": 0.0,
                "temperature": 0.0,
                "compression_ratio": 1.0
            }

            model_info = self.SUPPORTED_MODELS[self.model]
            self.log_with_emoji("info", "üìä", f"{model_info['name']}: —Å–æ–∑–¥–∞–Ω —Å–µ–≥–º–µ–Ω—Ç –∏–∑ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (json)")
            return [segment]

        else:
            # –î–ª—è text, srt, vtt —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            # –≠—Ç–∏ —Ñ–æ—Ä–º–∞—Ç—ã –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –ø—Ä—è–º–æ–≥–æ –≤—ã–≤–æ–¥–∞, –∞ –Ω–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            text_content = str(transcript) if transcript else ""
            if not text_content:
                self.log_with_emoji("warning", "‚ö†Ô∏è", f"–ú–æ–¥–µ–ª—å {self.model} –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –∫–æ–Ω—Ç–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ {self.response_format}")
                return []

            segment = {
                "id": 0,
                "start": 0.0,
                "end": 0.0,
                "text": text_content.strip(),
                "tokens": [],
                "avg_logprob": 0.0,
                "no_speech_prob": 0.0,
                "temperature": 0.0,
                "compression_ratio": 1.0
            }

            model_info = self.SUPPORTED_MODELS[self.model]
            self.log_with_emoji("info", "üìä", f"{model_info['name']}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ–Ω—Ç–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ {self.response_format}")
            return [segment]

    def get_model_info(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏."""
        return {
            "model": self.model,
            "language": self.language,
            **self.SUPPORTED_MODELS[self.model]
        }

    @classmethod
    def get_available_models(cls) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        return cls.SUPPORTED_MODELS.copy()

    def set_language(self, language: Optional[str]) -> None:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —è–∑—ã–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏."""
        self.language = language
        if language:
            self.log_with_emoji("info", "üåê", f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —è–∑—ã–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {language}")
        else:
            self.log_with_emoji("info", "üåê", "–Ø–∑—ã–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–±—Ä–æ—à–µ–Ω (–∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)")

    def estimate_cost(self, file_size_mb: float) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏."""
        cost_tier = self.SUPPORTED_MODELS[self.model]["cost_tier"]

        cost_estimates = {
            "low": f"~${file_size_mb * 0.006:.3f}",  # whisper-1: $0.006/min
            "medium": f"~${file_size_mb * 0.012:.3f}",  # gpt-4o-mini-transcribe: –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ 2 —Ä–∞–∑–∞ –¥–æ—Ä–æ–∂–µ
            "high": f"~${file_size_mb * 0.024:.3f}"  # gpt-4o-transcribe: –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ 4 —Ä–∞–∑–∞ –¥–æ—Ä–æ–∂–µ
        }

        return cost_estimates.get(cost_tier, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
