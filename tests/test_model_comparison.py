#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
–¢—Ä–µ–±—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö API –∫–ª—é—á–µ–π –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
"""

import pytest
import os
import time
from pathlib import Path
from typing import Dict, List
import json

from pipeline.transcription_agent import TranscriptionAgent


class TestModelComparison:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π"""
    
    @pytest.fixture(autouse=True)
    def setup(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–æ–≤"""
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            pytest.skip("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        self.test_audio = Path("tests/assets/test_audio.wav")
        if not self.test_audio.exists():
            pytest.skip(f"–¢–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.test_audio}")
    
    @pytest.mark.integration
    @pytest.mark.slow
    def test_all_models_transcription(self):
        """–¢–µ—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
        models = ["whisper-1", "gpt-4o-mini-transcribe", "gpt-4o-transcribe"]
        results = {}
        
        for model in models:
            print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä—É—é –º–æ–¥–µ–ª—å: {model}")
            
            try:
                agent = TranscriptionAgent(self.api_key, model)
                start_time = time.time()
                
                segments = agent.run(self.test_audio, "")
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                results[model] = {
                    "segments_count": len(segments),
                    "processing_time": processing_time,
                    "success": True,
                    "segments": segments[:3] if segments else [],  # –ü–µ—Ä–≤—ã–µ 3 —Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    "model_info": agent.get_model_info()
                }
                
                print(f"‚úÖ {model}: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∑–∞ {processing_time:.2f}—Å")
                
            except Exception as e:
                results[model] = {
                    "success": False,
                    "error": str(e),
                    "processing_time": None
                }
                print(f"‚ùå {model}: –û—à–∏–±–∫–∞ - {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        results_file = Path("tests/results/model_comparison.json")
        results_file.parent.mkdir(exist_ok=True)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        successful_models = [model for model, result in results.items() if result.get("success")]
        assert len(successful_models) > 0, "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —É—Å–ø–µ—à–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤–µ—Ä–Ω—É–ª–∏ —Å–µ–≥–º–µ–Ω—Ç—ã
        for model in successful_models:
            assert results[model]["segments_count"] > 0, f"–ú–æ–¥–µ–ª—å {model} –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤"
    
    @pytest.mark.integration
    def test_language_specific_transcription(self):
        """–¢–µ—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —è–∑—ã–∫–∞"""
        if not self.test_audio.exists():
            pytest.skip("–¢–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —è–∑—ã–∫–∞
        agent_with_lang = TranscriptionAgent(self.api_key, "gpt-4o-mini-transcribe", language="en")
        agent_without_lang = TranscriptionAgent(self.api_key, "gpt-4o-mini-transcribe")
        
        try:
            segments_with_lang = agent_with_lang.run(self.test_audio, "")
            segments_without_lang = agent_without_lang.run(self.test_audio, "")
            
            # –û–±–∞ –¥–æ–ª–∂–Ω—ã –≤–µ—Ä–Ω—É—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            assert len(segments_with_lang) > 0
            assert len(segments_without_lang) > 0
            
            print(f"–° —è–∑—ã–∫–æ–º: {len(segments_with_lang)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            print(f"–ë–µ–∑ —è–∑—ã–∫–∞: {len(segments_without_lang)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            
        except Exception as e:
            pytest.skip(f"–û—à–∏–±–∫–∞ API: {e}")
    
    @pytest.mark.integration
    def test_prompt_influence(self):
        """–¢–µ—Å—Ç –≤–ª–∏—è–Ω–∏—è prompt –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        if not self.test_audio.exists():
            pytest.skip("–¢–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        agent = TranscriptionAgent(self.api_key, "gpt-4o-mini-transcribe")
        
        prompts = [
            "",  # –ë–µ–∑ prompt
            "This is a technical discussion about AI and machine learning.",  # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            "The following is a conversation between two people."  # –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        ]
        
        results = {}
        
        for i, prompt in enumerate(prompts):
            try:
                segments = agent.run(self.test_audio, prompt)
                results[f"prompt_{i}"] = {
                    "prompt": prompt,
                    "segments_count": len(segments),
                    "first_segment_text": segments[0]["text"] if segments else ""
                }
                
            except Exception as e:
                results[f"prompt_{i}"] = {
                    "prompt": prompt,
                    "error": str(e)
                }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results_file = Path("tests/results/prompt_comparison.json")
        results_file.parent.mkdir(exist_ok=True)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã prompt —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {results_file}")
    
    def test_cost_estimation_accuracy(self):
        """–¢–µ—Å—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ü–µ–Ω–∫–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏"""
        file_sizes = [1.0, 5.0, 10.0, 25.0]  # MB
        
        for model in TranscriptionAgent.SUPPORTED_MODELS:
            agent = TranscriptionAgent("dummy_key", model)
            
            for size in file_sizes:
                cost = agent.estimate_cost(size)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –æ—Ü–µ–Ω–∫–∏
                assert cost.startswith("~$")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                cost_value = float(cost.replace("~$", ""))
                
                # –°—Ç–æ–∏–º–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏ —Å —Ä–∞–∑–º–µ—Ä–æ–º —Ñ–∞–π–ª–∞
                assert cost_value > 0
                
                # –î–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ
                if size > 1.0:
                    smaller_cost = agent.estimate_cost(1.0)
                    smaller_value = float(smaller_cost.replace("~$", ""))
                    assert cost_value > smaller_value
    
    def test_model_characteristics(self):
        """–¢–µ—Å—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –º–æ–¥–µ–ª–µ–π"""
        models = TranscriptionAgent.get_available_models()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—é —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        whisper_cost = models["whisper-1"]["cost_tier"]
        mini_cost = models["gpt-4o-mini-transcribe"]["cost_tier"]
        full_cost = models["gpt-4o-transcribe"]["cost_tier"]
        
        cost_hierarchy = ["low", "medium", "high"]
        
        assert whisper_cost == "low"
        assert mini_cost == "medium"
        assert full_cost == "high"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω—É–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        for model_name, model_info in models.items():
            assert model_info["supports_language"] is True
            assert model_info["supports_prompt"] is True
            assert model_info["max_file_size_mb"] == 25


class TestPerformanceMetrics:
    """–¢–µ—Å—Ç—ã –¥–ª—è –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def test_processing_time_logging(self):
        """–¢–µ—Å—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –º–µ—Ç—Ä–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è
        # –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API –≤—ã–∑–æ–≤–∞
        
        from unittest.mock import Mock, patch
        
        with patch('pipeline.transcription_agent.OpenAI') as mock_openai:
            # –ú–æ–∫–∞–µ–º –æ—Ç–≤–µ—Ç API
            mock_transcript = Mock()
            mock_transcript.segments = []
            mock_transcript.duration = 60.0  # 60 —Å–µ–∫—É–Ω–¥ –∞—É–¥–∏–æ
            
            mock_client = Mock()
            mock_client.audio.transcriptions.create.return_value = mock_transcript
            mock_openai.return_value = mock_client
            
            agent = TranscriptionAgent("test_key", "whisper-1")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç–∞
            import tempfile
            with tempfile.NamedTemporaryFile(suffix=".wav") as tmp_file:
                tmp_path = Path(tmp_file.name)
                
                # –ú–æ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                with patch.object(Path, 'stat') as mock_stat:
                    mock_stat.return_value.st_size = 1024 * 1024  # 1MB
                    
                    with patch.object(Path, 'exists', return_value=True):
                        segments = agent.run(tmp_path, "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ API –±—ã–ª –≤—ã–∑–≤–∞–Ω —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            mock_client.audio.transcriptions.create.assert_called_once()
            call_args = mock_client.audio.transcriptions.create.call_args[1]
            
            assert call_args["model"] == "whisper-1"
            assert call_args["response_format"] == "verbose_json"
            assert call_args["temperature"] == 0


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã—Ö —Ç–µ—Å—Ç–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    pytest.main([__file__, "-v", "-m", "not slow"])
