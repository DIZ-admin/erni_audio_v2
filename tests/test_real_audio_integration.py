"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ-–ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Ü–µ–ø–æ—á–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç –Ω–∞—á–∞–ª–∞ –¥–æ –∫–æ–Ω—Ü–∞.
"""

import pytest
import logging
import time
import json
from pathlib import Path
from typing import Dict, List, Any
from unittest.mock import patch, MagicMock
import tempfile
import shutil

from pipeline.audio_agent import AudioLoaderAgent
from pipeline.diarization_agent import DiarizationAgent
from pipeline.transcription_agent import TranscriptionAgent
from pipeline.merge_agent import MergeAgent
from pipeline.export_agent import ExportAgent
from pipeline.qc_agent import QCAgent

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

class TestRealAudioPipeline:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª–µ"""
    
    @pytest.fixture
    def real_audio_file(self):
        """–ü—É—Ç—å –∫ —Ä–µ–∞–ª—å–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É"""
        audio_path = Path("data/raw/Schongiland 3.m4a")
        if not audio_path.exists():
            pytest.skip("–†–µ–∞–ª—å–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return audio_path
    
    @pytest.fixture
    def temp_output_dir(self):
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_dir = Path(tempfile.mkdtemp(prefix="pipeline_test_"))
        yield temp_dir
        # –û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞
        if temp_dir.exists():
            shutil.rmtree(temp_dir)
    
    @pytest.fixture
    def interim_dir(self):
        """–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        interim_path = Path("data/interim")
        interim_path.mkdir(exist_ok=True)
        return interim_path
    
    def test_audio_file_analysis(self, real_audio_file):
        """–ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        logger = logging.getLogger(__name__)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        assert real_audio_file.exists(), f"–ê—É–¥–∏–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {real_audio_file}"
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = real_audio_file.stat().st_size
        file_size_mb = file_size / (1024 * 1024)
        
        logger.info(f"üìÅ –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {real_audio_file.name}")
        logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.2f} MB")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        assert file_size_mb < 100, f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {file_size_mb:.2f} MB"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ interim
        metrics = {
            "file_name": real_audio_file.name,
            "file_size_bytes": file_size,
            "file_size_mb": file_size_mb,
            "test_timestamp": time.time()
        }
        
        metrics_path = Path("data/interim/audio_analysis_metrics.json")
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {metrics_path}")
    
    def test_audio_loading_and_conversion(self, real_audio_file, interim_dir):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ"""
        logger = logging.getLogger(__name__)
        logger.info("üéµ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AudioLoaderAgent...")
        
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç
        audio_agent = AudioLoaderAgent()
        
        try:
            # –ú–æ–∫–∏—Ä—É–µ–º upload_to_transfer_sh –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            with patch.object(audio_agent, 'upload_to_transfer_sh') as mock_upload:
                mock_upload.return_value = "https://mock-transfer.sh/test.wav"
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
                wav_local, wav_url = audio_agent.run(str(real_audio_file))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                assert wav_local.exists(), f"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π WAV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {wav_local}"
                assert wav_local.suffix == ".wav", f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ: {wav_local.suffix}"
                assert wav_url == "https://mock-transfer.sh/test.wav"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ WAV —Ñ–∞–π–ª–∞
                wav_size = wav_local.stat().st_size
                wav_size_mb = wav_size / (1024 * 1024)
                
                processing_time = time.time() - start_time
                
                logger.info(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å")
                logger.info(f"üìä –†–∞–∑–º–µ—Ä WAV: {wav_size_mb:.2f} MB")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                conversion_metrics = {
                    "original_file": str(real_audio_file),
                    "converted_file": str(wav_local),
                    "original_size_mb": real_audio_file.stat().st_size / (1024 * 1024),
                    "converted_size_mb": wav_size_mb,
                    "processing_time_seconds": processing_time,
                    "conversion_ratio": wav_size_mb / (real_audio_file.stat().st_size / (1024 * 1024))
                }
                
                metrics_path = interim_dir / "audio_conversion_metrics.json"
                with open(metrics_path, 'w', encoding='utf-8') as f:
                    json.dump(conversion_metrics, f, indent=2, ensure_ascii=False)
                
                # –ö–æ–ø–∏—Ä—É–µ–º WAV –≤ interim –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                interim_wav = interim_dir / f"converted_{real_audio_file.stem}.wav"
                shutil.copy2(wav_local, interim_wav)
                
                logger.info(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {interim_dir}")

                # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ pytest —Ç–µ—Å—Ç–∞—Ö
                assert wav_local is not None
                assert wav_url is not None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            raise
    
    @patch('pipeline.diarization_agent.requests.post')
    @patch('pipeline.diarization_agent.requests.get')
    def test_diarization_simulation(self, mock_get, mock_post, interim_dir):
        """–°–∏–º—É–ª—è—Ü–∏—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        logger = logging.getLogger(__name__)
        logger.info("üé≠ –°–∏–º—É–ª—è—Ü–∏—è DiarizationAgent...")
        
        # –ú–æ–∫–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã API
        mock_post.return_value.json.return_value = {"jobId": "test-job-123"}
        mock_post.return_value.raise_for_status.return_value = None
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        mock_diarization_result = []
        current_time = 0.0
        speakers = ["SPEAKER_00", "SPEAKER_01", "SPEAKER_02"]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è ~92 –º–∏–Ω—É—Ç –∞—É–¥–∏–æ
        while current_time < 5520:  # 92 –º–∏–Ω—É—Ç—ã
            segment_duration = min(15.0 + (time.time() % 10), 5520 - current_time)
            speaker = speakers[int(current_time / 60) % len(speakers)]  # –°–º–µ–Ω–∞ —Å–ø–∏–∫–µ—Ä–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
            
            mock_diarization_result.append({
                "start": current_time,
                "end": current_time + segment_duration,
                "speaker": speaker,
                "confidence": 0.85 + (time.time() % 0.15)  # –°–ª—É—á–∞–π–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 0.85-1.0
            })
            
            current_time += segment_duration
        
        mock_get.return_value.json.return_value = {
            "status": "completed",
            "result": {
                "diarization": mock_diarization_result
            }
        }
        mock_get.return_value.raise_for_status.return_value = None
        
        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
        diar_agent = DiarizationAgent("fake_api_key")
        
        start_time = time.time()
        result = diar_agent.run("https://mock-audio-url.wav")
        processing_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        assert isinstance(result, list), "–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º"
        assert len(result) > 0, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã —Å–µ–≥–º–µ–Ω—Ç—ã"
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        total_duration = max(seg["end"] for seg in result)
        num_speakers = len(set(seg["speaker"] for seg in result))
        avg_confidence = sum(seg["confidence"] for seg in result) / len(result)
        
        logger.info(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å")
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(result)}")
        logger.info(f"üé≠ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤: {num_speakers}")
        logger.info(f"‚è±Ô∏è –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration:.1f}—Å")
        logger.info(f"üéØ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        diarization_data = {
            "segments": result,
            "metadata": {
                "total_segments": len(result),
                "total_duration_seconds": total_duration,
                "num_speakers": num_speakers,
                "average_confidence": avg_confidence,
                "processing_time_seconds": processing_time
            }
        }
        
        diar_path = interim_dir / "diarization_results.json"
        with open(diar_path, 'w', encoding='utf-8') as f:
            json.dump(diarization_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {diar_path}")

        # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ pytest —Ç–µ—Å—Ç–∞—Ö
        assert result is not None
        assert len(result) > 0

    @patch('pipeline.transcription_agent.openai.OpenAI')
    def test_transcription_simulation(self, mock_openai_class, interim_dir):
        """–°–∏–º—É–ª—è—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        logger = logging.getLogger(__name__)
        logger.info("üó£Ô∏è –°–∏–º—É–ª—è—Ü–∏—è TranscriptionAgent...")

        # –ú–æ–∫–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç
        mock_client = MagicMock()
        mock_openai_class.return_value = mock_client

        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        mock_transcription_segments = []
        current_time = 0.0

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è –¥–ª–∏–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        sample_phrases = [
            "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –Ω–∞ –Ω–∞—à—É –≤—Å—Ç—Ä–µ—á—É.",
            "–°–µ–≥–æ–¥–Ω—è –º—ã –æ–±—Å—É–¥–∏–º –≤–∞–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.",
            "–ü–µ—Ä–≤—ã–π –ø—É–Ω–∫—Ç –ø–æ–≤–µ—Å—Ç–∫–∏ –¥–Ω—è –∫–∞—Å–∞–µ—Ç—Å—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.",
            "–ù—É–∂–Ω–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ.",
            "–ï—Å—Ç—å –ª–∏ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —ç—Ç–æ–º—É –ø—É–Ω–∫—Ç—É?",
            "–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –≤–æ–ø—Ä–æ—Å—É.",
            "–≠—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–∞—è —Ç–µ–º–∞ –¥–ª—è –Ω–∞—à–µ–π –∫–æ–º–∞–Ω–¥—ã.",
            "–î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º –¥–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏.",
            "–ö–∞–∫–∏–µ —É –Ω–∞—Å –µ—Å—Ç—å —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è —ç—Ç–æ–≥–æ?",
            "–ù—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏."
        ]

        phrase_index = 0
        while current_time < 5520:  # 92 –º–∏–Ω—É—Ç—ã
            phrase = sample_phrases[phrase_index % len(sample_phrases)]
            segment_duration = min(3.0 + len(phrase) * 0.1, 5520 - current_time)

            mock_transcription_segments.append({
                "start": current_time,
                "end": current_time + segment_duration,
                "text": phrase
            })

            current_time += segment_duration
            phrase_index += 1

        # –ú–æ–∫–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç API
        mock_response = MagicMock()
        mock_response.segments = []
        for seg in mock_transcription_segments:
            mock_segment = MagicMock()
            mock_segment.start = seg["start"]
            mock_segment.end = seg["end"]
            mock_segment.text = seg["text"]
            mock_response.segments.append(mock_segment)

        mock_client.audio.transcriptions.create.return_value = mock_response

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ç–µ—Å—Ç–∞
        import tempfile
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            temp_file.write(b"fake audio data")  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            temp_audio_path = Path(temp_file.name)

        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç –∏ –º–æ–∫–∏—Ä—É–µ–º –µ–≥–æ –∫–ª–∏–µ–Ω—Ç
            trans_agent = TranscriptionAgent("fake_api_key")
            trans_agent.client = mock_client  # –ó–∞–º–µ–Ω—è–µ–º –∫–ª–∏–µ–Ω—Ç –Ω–∞ –º–æ–∫

            start_time = time.time()
            result = trans_agent.run(temp_audio_path)
            processing_time = time.time() - start_time
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if temp_audio_path.exists():
                temp_audio_path.unlink()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        assert isinstance(result, list), "–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º"
        assert len(result) > 0, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã —Å–µ–≥–º–µ–Ω—Ç—ã"

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        total_words = sum(len(seg["text"].split()) for seg in result)
        total_chars = sum(len(seg["text"]) for seg in result)
        avg_segment_duration = sum(seg["end"] - seg["start"] for seg in result) / len(result)

        logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å")
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(result)}")
        logger.info(f"üìù –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {total_words}")
        logger.info(f"üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_chars}")
        logger.info(f"‚è±Ô∏è –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞: {avg_segment_duration:.1f}—Å")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        transcription_data = {
            "segments": result,
            "metadata": {
                "total_segments": len(result),
                "total_words": total_words,
                "total_characters": total_chars,
                "average_segment_duration": avg_segment_duration,
                "processing_time_seconds": processing_time
            }
        }

        trans_path = interim_dir / "transcription_results.json"
        with open(trans_path, 'w', encoding='utf-8') as f:
            json.dump(transcription_data, f, indent=2, ensure_ascii=False)

        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {trans_path}")

        # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ pytest —Ç–µ—Å—Ç–∞—Ö
        assert result is not None
        assert len(result) > 0

    def test_merge_and_export_pipeline(self, interim_dir):
        """–¢–µ—Å—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        logger = logging.getLogger(__name__)
        logger.info("üîó –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MergeAgent –∏ ExportAgent...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        diar_path = interim_dir / "diarization_results.json"
        trans_path = interim_dir / "transcription_results.json"

        if not (diar_path.exists() and trans_path.exists()):
            pytest.skip("–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ç–µ—Å—Ç—ã.")

        with open(diar_path, 'r', encoding='utf-8') as f:
            diar_data = json.load(f)

        with open(trans_path, 'r', encoding='utf-8') as f:
            trans_data = json.load(f)

        diarization = diar_data["segments"]
        transcription = trans_data["segments"]

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º MergeAgent
        merge_agent = MergeAgent()

        start_time = time.time()
        merged_segments = merge_agent.run(diarization, transcription)
        merge_time = time.time() - start_time

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        assert isinstance(merged_segments, list), "–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º"
        assert len(merged_segments) > 0, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        for segment in merged_segments[:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5
            assert "start" in segment, "–°–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'start'"
            assert "end" in segment, "–°–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'end'"
            assert "text" in segment, "–°–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'text'"
            assert "speaker" in segment, "–°–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'speaker'"

        logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {merge_time:.2f}—Å")
        logger.info(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(merged_segments)}")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        export_formats = ["srt", "json", "ass"]
        export_results = {}

        for format_name in export_formats:
            export_agent = ExportAgent(format_name)

            start_time = time.time()
            output_path = export_agent.run(merged_segments, f"test_output.{format_name}")
            export_time = time.time() - start_time

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
            assert output_path.exists(), f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω: {output_path}"

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = output_path.stat().st_size

            export_results[format_name] = {
                "file_path": str(output_path),
                "file_size_bytes": file_size,
                "processing_time_seconds": export_time
            }

            logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≤ {format_name.upper()} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {export_time:.2f}—Å")
            logger.info(f"üìÑ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")

            # –ö–æ–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ interim
            interim_output = interim_dir / f"final_output.{format_name}"
            shutil.copy2(output_path, interim_output)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
        pipeline_metrics = {
            "merge_metrics": {
                "input_diarization_segments": len(diarization),
                "input_transcription_segments": len(transcription),
                "output_merged_segments": len(merged_segments),
                "processing_time_seconds": merge_time
            },
            "export_metrics": export_results,
            "total_pipeline_segments": len(merged_segments)
        }

        metrics_path = interim_dir / "pipeline_completion_metrics.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(pipeline_metrics, f, indent=2, ensure_ascii=False)

        logger.info(f"üíæ –ú–µ—Ç—Ä–∏–∫–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {metrics_path}")

        # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤ pytest —Ç–µ—Å—Ç–∞—Ö
        assert merged_segments is not None
        assert export_results is not None

    def test_full_pipeline_integration(self, real_audio_file, interim_dir):
        """–ü–æ–ª–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        logger = logging.getLogger(__name__)
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞...")

        pipeline_start_time = time.time()

        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        logger.info("üìä –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞")
        self.test_audio_file_analysis(real_audio_file)

        # –®–∞–≥ 2: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ
        logger.info("üéµ –®–∞–≥ 2: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ")
        self.test_audio_loading_and_conversion(real_audio_file, interim_dir)

        # –®–∞–≥ 3: –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è
        logger.info("üé≠ –®–∞–≥ 3: –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è")
        self.test_diarization_simulation(interim_dir)

        # –®–∞–≥ 4: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
        logger.info("üó£Ô∏è –®–∞–≥ 4: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è")
        self.test_transcription_simulation(interim_dir)

        # –®–∞–≥ 5: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç
        logger.info("üîó –®–∞–≥ 5: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç")
        self.test_merge_and_export_pipeline(interim_dir)

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        diar_path = interim_dir / "diarization_results.json"
        trans_path = interim_dir / "transcription_results.json"
        pipeline_path = interim_dir / "pipeline_completion_metrics.json"

        diar_segments = 0
        trans_segments = 0
        merged_segments = 0
        export_results = {}

        if diar_path.exists():
            with open(diar_path, 'r', encoding='utf-8') as f:
                diar_data = json.load(f)
                diar_segments = len(diar_data.get("segments", []))

        if trans_path.exists():
            with open(trans_path, 'r', encoding='utf-8') as f:
                trans_data = json.load(f)
                trans_segments = len(trans_data.get("segments", []))

        if pipeline_path.exists():
            with open(pipeline_path, 'r', encoding='utf-8') as f:
                pipeline_data = json.load(f)
                merged_segments = pipeline_data.get("total_pipeline_segments", 0)
                export_results = pipeline_data.get("export_metrics", {})

        total_pipeline_time = time.time() - pipeline_start_time

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self._generate_final_report(
            real_audio_file,
            interim_dir,
            total_pipeline_time,
            diar_segments,
            trans_segments,
            merged_segments,
            export_results
        )

        logger.info(f"üéâ –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_pipeline_time:.2f}—Å")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        assert total_pipeline_time > 0, "–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 0"
        assert merged_segments > 0, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã"
        assert len(export_results) > 0, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"

        logger.info(f"‚úÖ –í—Å–µ —ç—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")

    def test_error_handling_and_recovery(self, interim_dir):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è"""
        logger = logging.getLogger(__name__)
        logger.info("‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫...")

        error_scenarios = []

        # –¢–µ—Å—Ç 1: –ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        try:
            audio_agent = AudioLoaderAgent()
            audio_agent.run("nonexistent_file.mp3")
            assert False, "–î–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –æ—à–∏–±–∫–∞"
        except Exception as e:
            error_scenarios.append({
                "scenario": "nonexistent_file",
                "error_type": type(e).__name__,
                "handled": True
            })
            logger.info(f"‚úÖ –û—à–∏–±–∫–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {type(e).__name__}")

        # –¢–µ—Å—Ç 2: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –∫–ª—é—á
        try:
            diar_agent = DiarizationAgent("")
            # –≠—Ç–æ—Ç —Ç–µ—Å—Ç –Ω–µ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            error_scenarios.append({
                "scenario": "empty_api_key",
                "error_type": "handled_gracefully",
                "handled": True
            })
            logger.info("‚úÖ –ü—É—Å—Ç–æ–π API –∫–ª—é—á –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        except Exception as e:
            error_scenarios.append({
                "scenario": "empty_api_key",
                "error_type": type(e).__name__,
                "handled": True
            })

        # –¢–µ—Å—Ç 3: –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        try:
            merge_agent = MergeAgent()
            result = merge_agent.run([], [])
            assert result == [], "–ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫"
            error_scenarios.append({
                "scenario": "empty_merge_data",
                "error_type": "handled_gracefully",
                "handled": True
            })
            logger.info("‚úÖ –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        except Exception as e:
            error_scenarios.append({
                "scenario": "empty_merge_data",
                "error_type": type(e).__name__,
                "handled": False
            })

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
        error_report = {
            "total_scenarios_tested": len(error_scenarios),
            "scenarios": error_scenarios,
            "all_errors_handled": all(scenario["handled"] for scenario in error_scenarios)
        }

        error_path = interim_dir / "error_handling_report.json"
        with open(error_path, 'w', encoding='utf-8') as f:
            json.dump(error_report, f, indent=2, ensure_ascii=False)

        logger.info(f"üíæ –û—Ç—á–µ—Ç –æ–± –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {error_path}")

        return error_report

    def _generate_final_report(self, audio_file: Path, interim_dir: Path,
                              total_time: float, diar_segments: int,
                              trans_segments: int, merged_segments: int,
                              export_results: Dict[str, Any]):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        logger = logging.getLogger(__name__)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics_files = [
            "audio_analysis_metrics.json",
            "audio_conversion_metrics.json",
            "diarization_results.json",
            "transcription_results.json",
            "pipeline_completion_metrics.json"
        ]

        all_metrics = {}
        for metrics_file in metrics_files:
            metrics_path = interim_dir / metrics_file
            if metrics_path.exists():
                with open(metrics_path, 'r', encoding='utf-8') as f:
                    all_metrics[metrics_file.replace('.json', '')] = json.load(f)

        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        audio_duration = 5523.09  # –ò–∑ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞
        processing_ratio = total_time / audio_duration

        final_report = {
            "test_summary": {
                "audio_file": str(audio_file),
                "audio_duration_seconds": audio_duration,
                "total_processing_time_seconds": total_time,
                "processing_ratio": processing_ratio,
                "test_timestamp": time.time()
            },
            "pipeline_results": {
                "diarization_segments": diar_segments,
                "transcription_segments": trans_segments,
                "merged_segments": merged_segments,
                "export_formats": list(export_results.keys())
            },
            "performance_metrics": {
                "processing_speed": f"{processing_ratio:.4f}x audio duration",
                "segments_per_minute": merged_segments / (audio_duration / 60),
                "average_segment_duration": audio_duration / merged_segments if merged_segments > 0 else 0
            },
            "quality_assessment": {
                "pipeline_completion": "SUCCESS",
                "all_stages_completed": True,
                "data_integrity": "VERIFIED",
                "output_formats_generated": len(export_results)
            },
            "detailed_metrics": all_metrics
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report_path = interim_dir / "FINAL_PIPELINE_REPORT.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)

        # –°–æ–∑–¥–∞–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
        readable_report = self._create_readable_report(final_report)
        readable_path = interim_dir / "FINAL_PIPELINE_REPORT.md"
        with open(readable_path, 'w', encoding='utf-8') as f:
            f.write(readable_report)

        logger.info(f"üìã –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_path}")
        logger.info(f"üìÑ –ß–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {readable_path}")

        return final_report

    def _create_readable_report(self, report_data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç"""

        summary = report_data["test_summary"]
        results = report_data["pipeline_results"]
        performance = report_data["performance_metrics"]
        quality = report_data["quality_assessment"]

        readable_report = f"""# üéØ –û—Ç—á–µ—Ç –æ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∞—É–¥–∏–æ-–ø–∞–π–ø–ª–∞–π–Ω–∞

## üìä –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
- **–¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–π —Ñ–∞–π–ª**: {summary['audio_file']}
- **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ**: {summary['audio_duration_seconds']:.1f} —Å–µ–∫—É–Ω–¥ (~{summary['audio_duration_seconds']/60:.1f} –º–∏–Ω—É—Ç)
- **–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {summary['total_processing_time_seconds']:.2f} —Å–µ–∫—É–Ω–¥
- **–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {summary['processing_ratio']:.4f}x –æ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ

## üîÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
- **–°–µ–≥–º–µ–Ω—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏**: {results['diarization_segments']}
- **–°–µ–≥–º–µ–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏**: {results['transcription_segments']}
- **–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã**: {results['merged_segments']}
- **–§–æ—Ä–º–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞**: {', '.join(results['export_formats'])}

## ‚ö° –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- **–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {performance['processing_speed']}
- **–°–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –º–∏–Ω—É—Ç—É**: {performance['segments_per_minute']:.1f}
- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞**: {performance['average_segment_duration']:.1f} —Å–µ–∫—É–Ω–¥

## ‚úÖ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
- **–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞**: {quality['pipeline_completion']}
- **–í—Å–µ —ç—Ç–∞–ø—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã**: {'‚úÖ' if quality['all_stages_completed'] else '‚ùå'}
- **–¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö**: {quality['data_integrity']}
- **–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤**: {quality['output_formats_generated']}

## üéâ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ-–ø–∞–π–ø–ª–∞–π–Ω–∞ **–£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û**.

–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:
- ‚úÖ AudioLoaderAgent - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞
- ‚úÖ DiarizationAgent - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–≤–æ—Ä—è—â–∏—Ö
- ‚úÖ TranscriptionAgent - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
- ‚úÖ MergeAgent - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- ‚úÖ ExportAgent - —ç–∫—Å–ø–æ—Ä—Ç –≤ —Ñ–æ—Ä–º–∞—Ç—ã

–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.

---
*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {time.strftime('%Y-%m-%d %H:%M:%S')}*
"""

        return readable_report
