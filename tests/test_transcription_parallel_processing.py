# tests/test_transcription_parallel_processing.py

import pytest
import time
import os
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

from pipeline.transcription_agent import TranscriptionAgent


class TestTranscriptionParallelProcessing:
    """Ð¢ÐµÑÑ‚Ñ‹ Ð´Ð»Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð² TranscriptionAgent."""

    @pytest.fixture
    def agent(self):
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ TranscriptionAgent Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²."""
        # ÐœÐ¾ÐºÐ°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²
        with patch.dict(os.environ, {
            'OPENAI_API_KEY': 'test-openai-key',
            'PYANNOTE_API_KEY': 'test-pyannote-key'
        }):
            return TranscriptionAgent(api_key="test-key", model="whisper-1")

    @pytest.fixture
    def mock_chunk_files(self, tmp_path):
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²."""
        chunk_files = []
        for i in range(3):
            chunk_file = tmp_path / f"test_chunk_{i:03d}.wav"
            chunk_file.write_bytes(b"fake audio data" * 1000)  # ~15KB
            chunk_files.append(chunk_file)
        return chunk_files

    def test_parallel_configuration_initialization(self, agent):
        """Ð¢ÐµÑÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸."""
        assert hasattr(agent, 'max_concurrent_chunks')
        assert hasattr(agent, 'chunk_processing_timeout')
        assert hasattr(agent, 'parallel_stats')
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
        assert agent.max_concurrent_chunks == 3
        assert agent.chunk_processing_timeout == 1800  # 30 Ð¼Ð¸Ð½ÑƒÑ‚
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
        assert agent.parallel_stats["total_chunks_processed"] == 0
        assert agent.parallel_stats["concurrent_chunks_peak"] == 0
        assert agent.parallel_stats["total_parallel_time"] == 0.0
        assert agent.parallel_stats["chunks_failed"] == 0
        assert agent.parallel_stats["chunks_retried"] == 0

    def test_process_chunk_parallel_success(self, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾Ð´Ð½Ð¾Ð¹ Ñ‡Ð°ÑÑ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð°."""
        # ÐœÐ¾ÐºÐ°ÐµÐ¼ Ð¼ÐµÑ‚Ð¾Ð´ _transcribe_single_file
        mock_segments = [
            {"id": 0, "start": 0.0, "end": 5.0, "text": "Test segment 1"},
            {"id": 1, "start": 5.0, "end": 10.0, "text": "Test segment 2"}
        ]
        
        with patch.object(agent, '_transcribe_single_file', return_value=mock_segments):
            chunk_info = {
                "path": mock_chunk_files[0],
                "index": 0,
                "offset": 0.0,
                "prompt": "test prompt"
            }
            
            result = agent._process_chunk_parallel(chunk_info)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            assert result["success"] is True
            assert result["index"] == 0
            assert result["error"] is None
            assert len(result["segments"]) == 2
            assert result["processing_time"] > 0
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸ Ð½Ðµ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»Ð¸ÑÑŒ (offset = 0)
            assert result["segments"][0]["start"] == 0.0
            assert result["segments"][1]["start"] == 5.0

    def test_process_chunk_parallel_with_offset(self, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‡Ð°ÑÑ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð° Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼ ÑÐ¼ÐµÑ‰ÐµÐ½Ð¸ÐµÐ¼."""
        mock_segments = [
            {"id": 0, "start": 0.0, "end": 5.0, "text": "Test segment"}
        ]
        
        with patch.object(agent, '_transcribe_single_file', return_value=mock_segments):
            chunk_info = {
                "path": mock_chunk_files[0],
                "index": 1,
                "offset": 600.0,  # 10 Ð¼Ð¸Ð½ÑƒÑ‚
                "prompt": "test prompt"
            }
            
            result = agent._process_chunk_parallel(chunk_info)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸ ÑÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹
            assert result["segments"][0]["start"] == 600.0  # 0.0 + 600.0
            assert result["segments"][0]["end"] == 605.0    # 5.0 + 600.0

    def test_process_chunk_parallel_failure(self, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ‡Ð°ÑÑ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð°."""
        # ÐœÐ¾ÐºÐ°ÐµÐ¼ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð² _transcribe_single_file
        with patch.object(agent, '_transcribe_single_file', side_effect=Exception("Test error")):
            chunk_info = {
                "path": mock_chunk_files[0],
                "index": 0,
                "offset": 0.0,
                "prompt": "test prompt"
            }
            
            result = agent._process_chunk_parallel(chunk_info)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
            assert result["success"] is False
            assert result["index"] == 0
            assert "Test error" in result["error"]
            assert len(result["segments"]) == 0
            assert result["processing_time"] > 0
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð°
            assert agent.parallel_stats["chunks_failed"] == 1

    def test_process_chunks_parallel_success(self, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ñ„Ð°Ð¹Ð»Ð¾Ð²."""
        # ÐœÐ¾ÐºÐ°ÐµÐ¼ _process_chunk_parallel Ð´Ð»Ñ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        def mock_process_chunk(chunk_info):
            return {
                "index": chunk_info["index"],
                "segments": [{"id": 0, "start": 0.0, "end": 5.0, "text": f"Chunk {chunk_info['index']}"}],
                "offset": chunk_info["offset"],
                "success": True,
                "error": None,
                "processing_time": 1.0
            }
        
        with patch.object(agent, '_process_chunk_parallel', side_effect=mock_process_chunk):
            chunk_infos = [
                {"path": mock_chunk_files[i], "index": i, "offset": i * 600.0, "prompt": "test"}
                for i in range(3)
            ]
            
            results = agent._process_chunks_parallel(chunk_infos)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
            assert len(results) == 3

            # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾ Ð¸Ð½Ð´ÐµÐºÑÑƒ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
            results.sort(key=lambda x: x["index"])

            for i, result in enumerate(results):
                assert result["success"] is True
                assert result["index"] == i
                
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¿Ð¸Ðº Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½
            assert agent.parallel_stats["concurrent_chunks_peak"] >= 3

    def test_process_chunks_parallel_with_timeout(self, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð° Ð¿Ñ€Ð¸ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ."""
        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð°
        agent.chunk_processing_timeout = 0.1

        # ÐœÐ¾ÐºÐ°ÐµÐ¼ as_completed Ð´Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð¾ÑÐ° TimeoutError
        with patch('pipeline.transcription_agent.as_completed') as mock_as_completed:
            mock_as_completed.side_effect = concurrent.futures.TimeoutError("Test timeout")

            chunk_infos = [
                {"path": mock_chunk_files[0], "index": 0, "offset": 0.0, "prompt": "test"}
            ]

            # ÐœÐ¾ÐºÐ°ÐµÐ¼ ThreadPoolExecutor
            with patch('pipeline.transcription_agent.ThreadPoolExecutor') as mock_executor_class:
                mock_executor = Mock()
                mock_executor_class.return_value.__enter__.return_value = mock_executor
                mock_executor.submit.return_value = Mock()

                results = agent._process_chunks_parallel(chunk_infos)

                # ÐŸÑ€Ð¸ TimeoutError Ð² as_completed, Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð²ÐµÑ€Ð½ÑƒÑ‚ÑŒ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº
                # Ð¸Ð»Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÑƒ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼
                assert isinstance(results, list)

    def test_cleanup_chunk_files(self, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡Ð°ÑÑ‚ÐµÐ¹."""
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð»Ñ‹ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‚
        for chunk_file in mock_chunk_files:
            assert chunk_file.exists()
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹
        agent._cleanup_chunk_files(mock_chunk_files)
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð»Ñ‹ ÑƒÐ´Ð°Ð»ÐµÐ½Ñ‹
        for chunk_file in mock_chunk_files:
            assert not chunk_file.exists()

    def test_cleanup_chunk_files_with_missing_files(self, agent, tmp_path):
        """Ð¢ÐµÑÑ‚ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ð½ÐµÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² (Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¾ÑˆÐ¸Ð±Ð¾Ðº)."""
        non_existent_files = [
            tmp_path / "non_existent_1.wav",
            tmp_path / "non_existent_2.wav"
        ]
        
        # ÐÐµ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹
        agent._cleanup_chunk_files(non_existent_files)

    def test_log_parallel_statistics(self, agent, caplog):
        """Ð¢ÐµÑÑ‚ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸."""
        import logging
        
        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        caplog.set_level(logging.INFO)
        
        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        agent.parallel_stats["total_chunks_processed"] = 5
        agent.parallel_stats["concurrent_chunks_peak"] = 3
        agent.parallel_stats["total_parallel_time"] = 45.5
        agent.parallel_stats["chunks_failed"] = 1
        agent.parallel_stats["chunks_retried"] = 2
        
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        agent._log_parallel_statistics()
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð»Ð¾Ð³
        assert "ðŸ”„ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸" in caplog.text
        assert "Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ Ñ‡Ð°ÑÑ‚ÐµÐ¹=5" in caplog.text
        assert "Ð¿Ð¸Ðº Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ…=3" in caplog.text
        assert "Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸=45.5Ñ" in caplog.text
        assert "Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ñ…=1" in caplog.text
        assert "Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ…=2" in caplog.text

    def test_log_parallel_statistics_no_processing(self, agent, caplog):
        """Ð¢ÐµÑÑ‚ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð±Ñ‹Ð»Ð¾ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸."""
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð±ÐµÐ· Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        agent._log_parallel_statistics()
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð»Ð¾Ð³ Ð¿ÑƒÑÑ‚Ð¾Ð¹
        assert "ðŸ”„ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸" not in caplog.text

    @patch('pipeline.transcription_agent.ThreadPoolExecutor')
    def test_process_chunks_parallel_executor_usage(self, mock_executor_class, agent, mock_chunk_files):
        """Ð¢ÐµÑÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ ThreadPoolExecutor."""
        mock_executor = Mock()
        mock_executor_class.return_value.__enter__.return_value = mock_executor
        
        # ÐœÐ¾ÐºÐ°ÐµÐ¼ submit Ð¸ as_completed
        mock_future = Mock()
        mock_future.result.return_value = {
            "index": 0, "success": True, "segments": [], "offset": 0.0, 
            "error": None, "processing_time": 1.0
        }
        mock_executor.submit.return_value = mock_future
        
        with patch('pipeline.transcription_agent.as_completed', return_value=[mock_future]):
            chunk_infos = [
                {"path": mock_chunk_files[0], "index": 0, "offset": 0.0, "prompt": "test"}
            ]
            
            agent._process_chunks_parallel(chunk_infos)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ThreadPoolExecutor ÑÐ¾Ð·Ð´Ð°Ð½ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸
            mock_executor_class.assert_called_once_with(max_workers=agent.max_concurrent_chunks)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ submit Ð±Ñ‹Ð» Ð²Ñ‹Ð·Ð²Ð°Ð½
            mock_executor.submit.assert_called_once()

    def test_transcribe_large_file_parallel_integration(self, agent, tmp_path):
        """Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÑÑ‚ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð°."""
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»
        large_audio_file = tmp_path / "large_test_audio.wav"
        large_audio_file.write_bytes(b"fake large audio data" * 10000)  # ~150KB
        
        # ÐœÐ¾ÐºÐ°ÐµÐ¼ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°
        mock_chunks = [tmp_path / f"chunk_{i}.wav" for i in range(3)]
        for chunk in mock_chunks:
            chunk.write_bytes(b"fake chunk data")
        
        def mock_transcribe_single_file(*args, **kwargs):
            # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ€Ð°Ð·, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð±ÐµÐ¶Ð°Ñ‚ÑŒ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ in-place
            return [
                {"id": 0, "start": 0.0, "end": 5.0, "text": "Test segment"}
            ]

        with patch.object(agent, '_split_audio_file', return_value=mock_chunks), \
             patch.object(agent, '_transcribe_single_file', side_effect=mock_transcribe_single_file), \
             patch.object(agent, '_cleanup_chunk_files') as mock_cleanup:
            
            result = agent._transcribe_large_file(large_audio_file, "test prompt")
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            assert len(result) == 3  # 3 Ñ‡Ð°ÑÑ‚Ð¸ * 1 ÑÐµÐ³Ð¼ÐµÐ½Ñ‚ ÐºÐ°Ð¶Ð´Ð°Ñ

            # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾ start Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸
            result.sort(key=lambda x: x["start"])

            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ÐµÑÑ‚ÑŒ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð¼ÐµÑ‚ÐºÐ°Ð¼Ð¸
            start_times = [seg["start"] for seg in result]
            assert 0.0 in start_times      # ÐŸÐµÑ€Ð²Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ: 0 + 0
            assert 600.0 in start_times    # Ð’Ñ‚Ð¾Ñ€Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ: 0 + 600
            assert 1200.0 in start_times   # Ð¢Ñ€ÐµÑ‚ÑŒÑ Ñ‡Ð°ÑÑ‚ÑŒ: 0 + 1200

            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ID Ð¿ÐµÑ€ÐµÐ½ÑƒÐ¼ÐµÑ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾
            ids = [seg["id"] for seg in result]
            assert set(ids) == {0, 1, 2}
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ cleanup Ð±Ñ‹Ð» Ð²Ñ‹Ð·Ð²Ð°Ð½
            mock_cleanup.assert_called_once_with(mock_chunks)
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
            assert agent.parallel_stats["total_chunks_processed"] == 3
            assert agent.parallel_stats["total_parallel_time"] > 0
