#!/usr/bin/env python
# speech_pipeline.py

import argparse
import logging
import os
import sys
from pathlib import Path
from typing import List, Dict
import requests

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏–∑ –Ω–∞—à–µ–≥–æ –ø–∞–∫–µ—Ç–∞ pipeline
from pipeline.audio_agent import AudioLoaderAgent
from pipeline.diarization_agent import DiarizationAgent
from pipeline.qc_agent import QCAgent
from pipeline.transcription_agent import TranscriptionAgent
from pipeline.merge_agent import MergeAgent
from pipeline.export_agent import ExportAgent
from pipeline.utils import load_json, save_json
from pipeline.security_validator import SECURITY_VALIDATOR

def parse_args():
    p = argparse.ArgumentParser("speech_pipeline: multi-agent version")
    p.add_argument("input", help="audio/video FILE –∏–ª–∏ HTTPS URL (16 kHz WAV)")
    p.add_argument("-o", "--output", default="data/processed/transcript.srt",
                   help="–∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª")
    p.add_argument("--format", choices=["srt", "json", "ass"], default="srt",
                   help="—Ñ–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤")
    p.add_argument("--prompt", default="", help="–Ω–∞—á–∞–ª—å–Ω—ã–π Whisper prompt")
    p.add_argument("--remote-wav-url", help="–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å upload ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç HTTPS URL")
    p.add_argument("--voiceprints-dir", help="–∏–∑–≤–ª–µ—á—å WAV‚â§30—Å –Ω–∞ –∫–∞–∂–¥–æ–≥–æ speakers ‚Üí exit")
    p.add_argument("--identify", help="JSON mapping {voiceprintId:HumanName} ‚Üí –≤–∫–ª—é—á–∏—Ç—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é")

    # –û–ø—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    p.add_argument("--transcription-model",
                   choices=["whisper-1", "gpt-4o-mini-transcribe", "gpt-4o-transcribe"],
                   default="whisper-1",
                   help="–º–æ–¥–µ–ª—å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (whisper-1: –±—ã—Å—Ç—Ä–æ/–¥–µ—à–µ–≤–æ, gpt-4o-mini-transcribe: –±–∞–ª–∞–Ω—Å, gpt-4o-transcribe: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)")
    p.add_argument("--language",
                   help="–∫–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (en, ru, de, fr, es, etc.) - —É–ª—É—á—à–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å")
    p.add_argument("--show-cost-estimate", action="store_true",
                   help="–ø–æ–∫–∞–∑–∞—Ç—å –æ—Ü–µ–Ω–∫—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")

    # –û–ø—Ü–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ (—Ç–æ–ª—å–∫–æ pyannote.ai Media API)
    # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: OneDrive –∏ transfer.sh —É–¥–∞–ª–µ–Ω—ã –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

    return p.parse_args()

def sys_exit(msg: str):
    raise SystemExit(f"‚ùå  {msg}")

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ª–æ–≥–∞–º–∏"""
    from logging.handlers import RotatingFileHandler
    import json
    import datetime

    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤
    Path('logs').mkdir(exist_ok=True)

    # –ö–∞—Å—Ç–æ–º–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è JSON –ª–æ–≥–æ–≤
    class JSONFormatter(logging.Formatter):
        def format(self, record):
            log_entry = {
                'timestamp': datetime.datetime.fromtimestamp(record.created).isoformat(),
                'level': record.levelname,
                'logger': record.name,
                'message': record.getMessage(),
                'module': record.module,
                'function': record.funcName,
                'line': record.lineno
            }
            if record.exc_info:
                log_entry['exception'] = self.formatException(record.exc_info)
            return json.dumps(log_entry, ensure_ascii=False)

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)

    # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # Console handler (—á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    root_logger.addHandler(console_handler)

    # File handler —Å —Ä–æ—Ç–∞—Ü–∏–µ–π (JSON —Ñ–æ—Ä–º–∞—Ç)
    file_handler = RotatingFileHandler(
        'logs/pipeline.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(JSONFormatter())
    root_logger.addHandler(file_handler)

    # –û—Ç–¥–µ–ª—å–Ω—ã–π handler –¥–ª—è –æ—à–∏–±–æ–∫
    error_handler = RotatingFileHandler(
        'logs/errors.log',
        maxBytes=5*1024*1024,  # 5MB
        backupCount=3,
        encoding='utf-8'
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(JSONFormatter())
    root_logger.addHandler(error_handler)

def ensure_directories():
    """–°–æ–∑–¥–∞—ë—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
    directories = [
        "data/raw",
        "data/interim",
        "data/processed",
        "voiceprints"
    ]
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)

def validate_input_file(input_path: str) -> None:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
    logger = logging.getLogger(__name__)

    # –ï—Å–ª–∏ —ç—Ç–æ URL, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é URL
    if input_path.startswith(('http://', 'https://')):
        is_valid, message = SECURITY_VALIDATOR.validate_url(input_path)
        if not is_valid:
            raise ValueError(f"–ù–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π URL: {message}")
        logger.info(f"–í—Ö–æ–¥–Ω–æ–π URL –≤–∞–ª–∏–¥–µ–Ω: {input_path}")
        return

    # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é
    file_path = Path(input_path)
    is_valid, message = SECURITY_VALIDATOR.validate_file(file_path)
    if not is_valid:
        raise ValueError(f"–§–∞–π–ª –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {message}")

    logger.info(f"–§–∞–π–ª –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {message}")

def show_cost_estimates(file_path: str, transcription_model: str) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    logger = logging.getLogger(__name__)

    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if file_path.startswith(('http://', 'https://')):
            # –î–ª—è URL –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —á–µ—Ä–µ–∑ HEAD –∑–∞–ø—Ä–æ—Å
            try:
                response = requests.head(file_path, timeout=10)
                file_size_mb = int(response.headers.get('content-length', 0)) / (1024 * 1024)
                if file_size_mb == 0:
                    file_size_mb = 10  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è URL
            except:
                file_size_mb = 10  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        else:
            # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            file_size_mb = Path(file_path).stat().st_size / (1024 * 1024)

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        from pipeline.transcription_agent import TranscriptionAgent

        print("\nüí∞ –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏:")
        print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.1f} MB")
        print("‚îÄ" * 60)

        for model_name, model_info in TranscriptionAgent.SUPPORTED_MODELS.items():
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            temp_agent = TranscriptionAgent("dummy_key", model_name)
            cost_estimate = temp_agent.estimate_cost(file_size_mb)

            # –û—Ç–º–µ—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            marker = "üëâ " if model_name == transcription_model else "   "

            print(f"{marker}{model_info['name']:<25} | {cost_estimate:>10} | {model_info['cost_tier']}")

        print("‚îÄ" * 60)
        print("üí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –û—Ü–µ–Ω–∫–∏ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏")
        print()

    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ—Ü–µ–Ω–∫—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏: {e}")

def main():
    import time
    start_time = time.time()

    args = parse_args()

    # 0) –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    setup_logging()
    ensure_directories()

    logger = logging.getLogger(__name__)
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Speech Pipeline", extra={
        'input_file': args.input,
        'output_format': args.format,
        'transcription_model': args.transcription_model,
        'language': args.language,
        'pipeline_version': '2.0'
    })

    try:
        # 1) –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        validate_input_file(args.input)

        # 2) –ü–æ–∫–∞–∑–∞—Ç—å –æ—Ü–µ–Ω–∫—É —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
        if args.show_cost_estimate:
            show_cost_estimates(args.input, args.transcription_model)

        # 3) –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π
        PYANNOTE_KEY = os.getenv("PYANNOTEAI_API_TOKEN") or os.getenv("PYANNOTE_API_KEY") or sys_exit("Missing PYANNOTEAI_API_TOKEN or PYANNOTE_API_KEY")
        OPENAI_KEY   = os.getenv("OPENAI_API_KEY")   or sys_exit("Missing OPENAI_API_KEY")

        # 4) –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        from pipeline.transcription_agent import TranscriptionAgent
        model_info = TranscriptionAgent.SUPPORTED_MODELS.get(args.transcription_model, {})
        logger.info(f"üéØ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {model_info.get('name', args.transcription_model)}")
        if args.language:
            logger.info(f"üåç –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —è–∑—ã–∫: {args.language}")

    except (FileNotFoundError, ValueError) as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        sys.exit(1)

    # 2) AudioLoaderAgent ‚Üí (wav_local, wav_url)
    logger.info(f"[1/5] üéµ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –∞—É–¥–∏–æ: {args.input}")
    try:
        logger.info("üìÅ –ú–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏: pyannote.ai Media API (–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)")

        audio_agent = AudioLoaderAgent(
            remote_wav_url=args.remote_wav_url,
            pyannote_api_key=PYANNOTE_KEY
        )
        wav_local, wav_url = audio_agent.run(args.input)
        logger.info(f"‚úÖ –ê—É–¥–∏–æ –≥–æ—Ç–æ–≤–æ: {wav_local} ‚Üí {wav_url}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π WAV —Ñ–∞–π–ª
        input_name = Path(args.input).stem
        interim_wav = Path("data/interim") / f"{input_name}_converted.wav"
        import shutil
        shutil.copy2(wav_local, interim_wav)
        logger.debug(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π WAV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {interim_wav}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
        sys.exit(1)

    # 3) DiarizationAgent ‚Üí raw_diar (List[Dict])
    logger.info("[2/5] üé§ –ó–∞–ø—É—Å–∫ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏...")
    use_identify = bool(args.identify)
    voiceprint_ids = []
    if use_identify:
        mapping = load_json(Path(args.identify))  # { "vp_uuid": "Alice", ... }
        voiceprint_ids = list(mapping.keys())
        logger.info(f"–†–µ–∂–∏–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {len(voiceprint_ids)} –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç–ø–µ—á–∞—Ç–∫–æ–≤")

    try:
        diar_agent = DiarizationAgent(api_key=PYANNOTE_KEY,
                                      use_identify=use_identify,
                                      voiceprint_ids=voiceprint_ids)
        raw_diar: List[Dict] = diar_agent.run(wav_url)
        logger.info(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(raw_diar)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        diar_file = Path("data/interim") / f"{input_name}_diarization.json"
        save_json(raw_diar, diar_file)
        logger.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {diar_file}")
    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Pyannote API: {e}")
        logger.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞")
        sys.exit(1)
    except RuntimeError as e:
        if "not-ready" in str(e):
            logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏")
            logger.error("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–º –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–º")
        else:
            logger.error(f"–û—à–∏–±–∫–∞ Pyannote API: {e}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        sys.exit(1)

    # QC Agent (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç–ø–µ—á–∞—Ç–∫–æ–≤)
    qc_agent = QCAgent(manifest_dir=Path(args.voiceprints_dir) if args.voiceprints_dir else None,
                       per_speaker_sec=30)
    qc_result = qc_agent.run(wav_local, raw_diar)
    if args.voiceprints_dir:
        logger.info(f"‚úÖ –ì–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–ø–µ—á–∞—Ç–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {args.voiceprints_dir}")
        return

    # –ï—Å–ª–∏ –±—ã–ª–æ identify, –Ω—É–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –∏–º–µ–Ω–∞ –≤ raw_diar
    if use_identify:
        # mapping = { "vp_uuid": "Alice", ‚Ä¶ }
        for seg in raw_diar:
            seg["speaker"] = mapping.get(seg["speaker"], seg["speaker"])
        logger.info("‚úÖ –ü—Ä–∏–º–µ–Ω—ë–Ω –º–∞–ø–ø–∏–Ω–≥ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –æ—Ç–ø–µ—á–∞—Ç–∫–æ–≤")

    # 4) TranscriptionAgent ‚Üí whisper_segments (List[Dict])
    model_name = TranscriptionAgent.SUPPORTED_MODELS.get(args.transcription_model, {}).get('name', args.transcription_model)
    logger.info(f"[3/5] üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é —á–µ—Ä–µ–∑ {model_name}...")
    try:
        trans_agent = TranscriptionAgent(
            api_key=OPENAI_KEY,
            model=args.transcription_model,
            language=args.language
        )

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = trans_agent.get_model_info()
        logger.info(f"üîß –ú–æ–¥–µ–ª—å: {model_info['name']} ({model_info['cost_tier']} cost)")

        whisper_segments = trans_agent.run(wav_local, args.prompt)
        logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(whisper_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        whisper_file = Path("data/interim") / f"{input_name}_transcription.json"
        save_json(whisper_segments, whisper_file)
        logger.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {whisper_file}")
    except requests.exceptions.RequestException as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI API: {e}")
        logger.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞")
        sys.exit(1)
    except Exception as e:
        error_msg = str(e).lower()
        if "rate limit" in error_msg or "quota" in error_msg:
            logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAI API")
            logger.error("–ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –ø–ª–∞–Ω –ø–æ–¥–ø–∏—Å–∫–∏")
        elif "invalid" in error_msg and "key" in error_msg:
            logger.error("–ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI")
            logger.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å OPENAI_API_KEY")
        else:
            logger.error(f"–û—à–∏–±–∫–∞ OpenAI API: {e}")
        sys.exit(1)

    # 5) MergeAgent ‚Üí merged_segments (List[{"start","end","speaker","text"}])
    logger.info("[4/5] üîó –û–±—ä–µ–¥–∏–Ω—è—é –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π...")
    merge_agent = MergeAgent()
    merged_segments = merge_agent.run(raw_diar, whisper_segments)
    logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(merged_segments)} —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    merged_file = Path("data/interim") / f"{input_name}_merged.json"
    save_json(merged_segments, merged_file)
    logger.debug(f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {merged_file}")

    # 6) ExportAgent ‚Üí —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª (SRT/JSON/ASS)
    logger.info(f"[5/5] üíæ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é –≤ {args.format.upper()}...")
    export_agent = ExportAgent(format=args.format)
    out_path = Path(args.output)
    export_agent.run(merged_segments, out_path)
    logger.info(f"üéâ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    end_time = time.time()
    total_time = end_time - start_time
    logger.info("‚ú® Speech Pipeline –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ", extra={
        'total_time_seconds': round(total_time, 2),
        'total_segments': len(merged_segments),
        'output_file': str(out_path),
        'success': True
    })

if __name__ == "__main__":
    main()
